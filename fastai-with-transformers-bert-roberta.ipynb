{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fastai with HuggingFace ğŸ¤—Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\n",
    "\n",
    "![fastai + Transformers](https://i.ibb.co/qspmrcm/fastai-transformers-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. This implementation is a supplement of the Medium article [\"Fastai with ğŸ¤—Transformers (BERT, RoBERTa, XLNet, XLM, DistilBERT)\"](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376).\n",
    "\n",
    "**Also, remember the upvote button is next to the fork button, and it's free too!** ğŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction : Story of transfer learning in NLP\n",
    "In early 2018, Jeremy Howard (co-founder of fast.ai) and Sebastian Ruder introduced the  [Universal Language Model Fine-tuning for Text Classification](https://medium.com/r/?url=https%3A%2F%2Farxiv.org%2Fpdf%2F1801.06146.pdf) (ULMFiT) method. ULMFiT was the first **Transfer Learning** method applied to NLP. As a result, besides significantly outperforming many state-of-the-art tasks, it allowed, with only 100 labeled examples, to match performances equivalent to models trained on 100Ã—  more data.\n",
    "\n",
    "The first time I heard about ULMFiT was during a [fast.ai course](https://course.fast.ai/videos/?lesson=4) given by Jeremy Howard. He demonstrated how it was easy â€Š-â€Š thanks to the ``fastai`` library â€Š-â€Š to implement the complete ULMFit method with only a few lines of codes. In his demo, he used an AWD-LSTM neural network pre-trained on Wikitext-103 and get rapidly state-of-the-art results. He also explained key techniques - also demonstrated in ULMFiT - to fine-tune the models like **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**.\n",
    "\n",
    "Since the introduction of ULMFiT, **Transfer Learning** became very popular in NLP and yet Google (BERT, Transformer-XL, XLNet), Facebook (RoBERTa, XLM) or even OpenAI (GPT, GPT-2) begin to pre-train their own model on very large corpora. This time, instead of using the AWD-LSTM neural network, they all used a more powerful architecture based on the Transformer (cf. [Attention is all you need](https://arxiv.org/abs/1706.03762)).\n",
    "\n",
    "Although these models are powerful, ``fastai`` do not integrate all of them. Fortunately, [HuggingFace](https://huggingface.co/) ğŸ¤— created the well know [transformers library](https://github.com/huggingface/transformers). Formerly knew as ``pytorch-transformers`` or ``pytorch-pretrained-bert``, this library brings together over 40 state-of-the-art pre-trained NLP models (BERT, GPT-2, RoBERTa, CTRLâ€¦). The implementation gives interesting additional utilities like tokenizer, optimizer or scheduler.\n",
    "\n",
    "The ``transformers`` library can be self-sufficient but incorporating it within the ``fastai`` library provides simpler implementation compatible with powerful fastai tools like  **Discriminate Learning Rate**, **Gradual Unfreezing** or **Slanted Triangular Learning Rates**. The point here is to allow anyone â€” expert or non-expert â€” to get easily state-of-the-art results and to â€œmake NLP uncool againâ€.\n",
    "\n",
    "It worth noting that the integration of the HuggingFace ``transformers`` library in ``fastai`` has already been demonstrated in:\n",
    "* Keita Kurita's article [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) which makes ``pytorch_pretrained_bert`` library compatible with ``fastai``.\n",
    "* Dev Sharma's article [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) which makes ``pytorch_transformers`` library compatible with ``fastai``.\n",
    "\n",
    "Although these articles are of high quality, some part of their demonstration is not anymore compatible with the last version of ``transformers``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ›  Integrating transformers with fastai for multiclass classification\n",
    "Before beginning the implementation, note that integrating ``transformers`` within ``fastai`` can be done in multiple different ways. For that reason, I decided to bring simple solutions, that are the most generic and flexible. More precisely, I try to make the minimum of modification in both libraries while making them compatible with the maximum amount of transformer architectures.\n",
    "\n",
    "Note that in addition to this NoteBook and the [Medium article](https://medium.com/p/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2?source=email-29c8f5cf1dc4--writer.postDistributed&sk=119c3e5d748b2827af3ea863faae6376), I made another version available on my GitHub(TODO add link)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries Installation\n",
    "Before starting the implementation, you will need to install the ``fastai`` and ``transformers`` libraries. To do so, just follow the instructions [here](https://github.com/fastai/fastai/blob/master/README.md#installation) and [here](https://github.com/huggingface/transformers#installation).\n",
    "\n",
    "In Kaggle, the ``fastai`` library is already installed. So you just have to instal ``transformers`` with :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading https://files.pythonhosted.org/packages/70/1a/364556102943cacde1ee00fdcae3b1615b39e52649eddbf54953e5b144c9/transformers-2.2.1-py3-none-any.whl (364kB)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.9.253)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers) (0.1.83)\n",
      "Collecting sacremoses\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from transformers) (4.36.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from transformers) (2019.8.19)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from transformers) (1.16.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (1.12.253)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.253->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.253->boto3->transformers) (2.8.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=05a0283d56f90c323b2973e21d32088c18c8f4628f968acf91cd4a6911a14c8a\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.35 transformers-2.2.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current versions of the fastai and transformers libraries are respectively 1.0.58 and 2.1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.58\n",
      "transformers version : 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¬ The exampleÂ task\n",
    "The chosen task is a multi-class text classification on [Movie Reviews](https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/overview).\n",
    "\n",
    "For each text movie review, the model has to predict a label for the sentiment. We evaluate the outputs of the model on classification accuracy. The sentiment labels are:\n",
    "* 0 â†’ Negative\n",
    "* 1 â†’ Somewhat negative\n",
    "* 2 â†’ Neutral\n",
    "* 3 â†’ Somewhat positive\n",
    "* 4 â†’ Positive\n",
    "\n",
    "The data is loaded into a ``DataFrame`` using ``pandas``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv\n",
      "/kaggle/input/sentiment-analysis-on-movie-reviews/test.tsv.zip\n",
      "/kaggle/input/sentiment-analysis-on-movie-reviews/train.tsv.zip\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156060, 4) (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = Path(\"..\") / \"/kaggle/input/sentiment-analysis-on-movie-reviews\"\n",
    "train = pd.read_csv(DATA_ROOT / 'train.tsv.zip', sep=\"\\t\")\n",
    "test = pd.read_csv(DATA_ROOT / 'test.tsv.zip', sep=\"\\t\")\n",
    "print(train.shape,test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that in the dataset there are no individual movie reviews but rather phrases taken out of context and split into smaller parts, each with an assigned sentiment label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main transformers classes\n",
    "In ``transformers``, each model architecture is associated with 3 main types of classes:\n",
    "* A **model class** to load/store a particular pre-train model.\n",
    "* A **tokenizer class** to pre-process the data and make it compatible with a particular model.\n",
    "* A **configuration class** to load/store the configuration of a particular model.\n",
    "\n",
    "For example, if you want to use the Bert architecture for text classification, you would use [``BertForSequenceClassification``](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) for the **model class**, [``BertTokenizer``](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer) for the **tokenizer class** and [``BertConfig``](https://huggingface.co/transformers/model_doc/bert.html#bertconfig) for the **configuration class**.Â \n",
    "\n",
    "In order to switch easily between classes â€Š-â€Š each related to a specific model type â€Š-â€Š I created a dictionary that allows loading the correct classes by just specifying the correct model type name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see later, that those classes share a common class method ``from_pretrained(pretrained_model_name,Â ...)``. In our case, the parameter ``pretrained_model_name`` is a string with the shortcut name of a pre-trained model/tokenizer/configuration to load, e.g ``'bert-base-uncased'``. We can find all the shortcut names in the transformers documentation [here](https://huggingface.co/transformers/pretrained_models.html#pretrained-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "\n",
    "# model_type = 'bert'\n",
    "# pretrained_model_name='bert-base-uncased'\n",
    "\n",
    "# model_type = 'distilbert'\n",
    "# pretrained_model_name = 'distilbert-base-uncased'\n",
    "\n",
    "#model_type = 'xlm'\n",
    "#pretrained_model_name = 'xlm-clm-enfr-1024'\n",
    "\n",
    "#model_type = 'xlnet'\n",
    "#pretrained_model_name = 'xlnet-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the available values for ``pretrained_model_name`` (shortcut names) corresponding to the ``model_type`` used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that in this case, we use the ``transformers`` library only for a multi-class text classification task. For that reason, this tutorial integrates only the transformer architectures that have a model for sequence classification implemented. These model types areÂ :\n",
    "* BERT (from Google)\n",
    "* XLNet (from Google/CMU)\n",
    "* XLM (from Facebook)\n",
    "* RoBERTa (from Facebook)\n",
    "* DistilBERT (from HuggingFace)\n",
    "\n",
    "However, if you want to go furtherâ€Š-â€Šby implementing another type of model or NLP taskâ€Š-â€Šthis tutorial still an excellent starter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to set the seed for generating random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "\n",
    "To match pre-training, we have to format the model input sequence in a specific format.\n",
    "To do so, you have to first **tokenize** and then **numericalize** the texts correctly.\n",
    "The difficulty here is that each pre-trained model, that we will fine-tune, requires exactly the same specific pre-processâ€Š-â€Š**tokenization** & **numericalization**â€Š-â€Šthan the pre-process used during the pre-train part.\n",
    "Fortunately, the **tokenizer class** from ``transformers`` provides the correct pre-process tools that correspond to each pre-trained model.\n",
    "\n",
    "In the ``fastai`` library, data pre-processing is done automatically during the creation of the ``DataBunch``. \n",
    "As you will see in the ``DataBunch`` implementation, the **tokenizer** and **numericalizer** are passed in the processor argument under the following format :\n",
    "\n",
    "``processor = [TokenizeProcessor(tokenizer=tokenizer,...), NumericalizeProcessor(vocab=vocab,...)]``\n",
    "\n",
    "Let's first analyse how we can integrate the ``transformers`` **tokenizer** within the ``TokenizeProcessor`` function.\n",
    "\n",
    "#### Custom Tokenizer\n",
    "This part can be a little bit confusing because a lot of classes are wrapped in each other and with similar names.\n",
    "To resume, if we look attentively at the ``fastai`` implementation, we notice thatÂ :\n",
    "1. The [``TokenizeProcessor`` object](https://docs.fast.ai/text.data.html#TokenizeProcessor) takes as ``tokenizer`` argument a ``Tokenizer`` object.\n",
    "2. The [``Tokenizer`` object](https://docs.fast.ai/text.transform.html#Tokenizer) takes as ``tok_func`` argument a ``BaseTokenizer`` object.\n",
    "3. The [``BaseTokenizer`` object](https://docs.fast.ai/text.transform.html#BaseTokenizer) implement the function ``tokenizer(t:str) â†’ List[str]`` that take a text ``t`` and returns the list of its tokens.\n",
    "\n",
    "Therefore, we can simply create a new class ``TransformersBaseTokenizer`` that inherits from ``BaseTokenizer`` and overwrite a new ``tokenizer`` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898823/898823 [00:00<00:00, 5138688.16B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456318/456318 [00:00<00:00, 3701252.96B/s]\n"
     ]
    }
   ],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation, be carefull about 3 things :\n",
    "1. As we are not using RNN, we have to limit the sequence length to the model input size.\n",
    "2. Most of the models require special tokens placed at the beginning and end of the sequences.\n",
    "3. Some models like RoBERTa require a space to start the input string. For those models, the encoding methods should be called with ``add_prefix_space`` set to ``True``.\n",
    "\n",
    "Below, you can find the resume of each pre-process requirement for the 5 model types used in this tutorial. You can also find this information on the [HuggingFace documentation](https://huggingface.co/transformers/) in each model section.\n",
    "\n",
    "    bert:       [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "    roberta:    [CLS] + prefix_space + tokens + [SEP] + padding\n",
    "    \n",
    "    distilbert: [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "    xlm:        [CLS] + tokens + [SEP] + padding\n",
    "\n",
    "    xlnet:      padding + [CLS] + tokens + [SEP]\n",
    "    \n",
    "It is worth noting that we don't add padding in this part of the implementation.Â \n",
    "As we will see later, ``fastai`` manage it automatically during the creation of the ``DataBunch``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Numericalizer\n",
    "\n",
    "In ``fastai``, [``NumericalizeProcessor``  object](https://docs.fast.ai/text.data.html#NumericalizeProcessor) takes as ``vocab`` argument a [``Vocab`` object](https://docs.fast.ai/text.transform.html#Vocab). \n",
    "From this analyse, we suggest two ways to adapt the fastai numericalizer:\n",
    "1. You can, like decribed in the [Dev Sharma's article](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Section *1. Setting Up the Tokenizer*), retreive the list of tokens and create a ``Vocab`` object.\n",
    "2. Create a new class ``TransformersVocab`` that inherits from ``Vocab`` and overwrite ``numericalize`` and ``textify`` functions.\n",
    "\n",
    "Even if the first solution seems to be simpler, ``Transformers`` does not provide, for all models, a straightforward way to retreive his list of tokens. \n",
    "Therefore, I implemented the second solution, which runs for each model type.\n",
    "It consists of using the functions ``convert_tokens_to_ids`` and ``convert_ids_to_tokens`` in respectively ``numericalize`` and ``textify``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom processor\n",
    "Now that we have our custom **tokenizer** and **numericalizer**, we can create the custom **processor**. Notice we are passing the ``include_bos = False`` and ``include_eos = False`` options. This is because ``fastai`` adds its own special tokens by default which interferes with the ``[CLS]`` and ``[SEP]`` tokens added by our custom tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Databunch\n",
    "For the DataBunch creation, you have to pay attention to set the processor argument to our new custom processor ``transformer_processor`` and manage correctly the padding.\n",
    "\n",
    "As mentioned in the HuggingFace documentation, BERT, RoBERTa, XLM and DistilBERT are models with absolute position embeddings, so it's usually advised to pad the inputs on the right rather than the left. Regarding XLNET, it is a model with relative position embeddings, therefore, you can either pad the inputs on the right or on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sal', 'ut', 'Ä c', 'Ä est', 'Ä mo', 'i', ',', 'Ä Hello', 'Ä it', 'Ä s', 'Ä me']\n",
      "[18111, 1182, 740, 3304, 7458, 118, 6, 20920, 24, 579, 162]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sal', 'ut', 'Ä c', 'Ä est', 'Ä mo', 'i', ',', 'Ä Hello', 'Ä it', 'Ä s', 'Ä me']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = transformer_tokenizer.tokenize('Salut c est moi, Hello it s me')\n",
    "print(tokens)\n",
    "ids = transformer_tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(ids)\n",
    "transformer_tokenizer.convert_ids_to_tokens(ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is multible ways to create a DataBunch, in our implementation, we use [the data block API](https://docs.fast.ai/data_block.html#The-data-block-API), which gives more flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch = (TextList.from_df(train, cols='Phrase', processor=transformer_processor)\n",
    "             .split_by_rand_pct(0.1,seed=seed)\n",
    "             .label_from_df(cols= 'Sentiment')\n",
    "             .add_test(test)\n",
    "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and tokenizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] token : <s>\n",
      "[SEP] token : </s>\n",
      "[PAD] token : <pad>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ä - L RB - Ä City Ä - RR B - Ä reminds Ä us Ä how Ä realistically Ä nuanced Ä a Ä Robert Ä De Ä N iro Ä performance Ä can Ä be Ä when Ä he Ä is Ä not Ä more Ä luc r atively Ä engaged Ä in Ä the Ä shameless Ä self - car ic ature Ä of Ä ` Ä Analy ze Ä This Ä ' Ä - L RB - Ä 1999 Ä - RR B - Ä and Ä ` Ä Analy ze Ä That Ä , Ä ' Ä promised Ä - L RB - Ä or Ä threatened Ä -</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ä The Ä real Ä triumph s Ä in Ä Ig by Ä come Ä from Ä Philippe Ä , Ä who Ä makes Ä Oliver Ä far Ä more Ä interesting Ä than Ä the Ä character Ä ' s Ä lines Ä would Ä suggest Ä , Ä and Ä Sar andon Ä , Ä who Ä could Ä n 't Ä be Ä better Ä as Ä a Ä cruel Ä but Ä weird ly Ä lik able Ä WAS P Ä mat ron Ä . &lt;/s&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ä Parker Ä should Ä be Ä comm ended Ä for Ä taking Ä a Ä fresh Ä approach Ä to Ä familiar Ä material Ä , Ä but Ä his Ä determination Ä to Ä remain Ä true Ä to Ä the Ä original Ä text Ä leads Ä him Ä to Ä adopt Ä a Ä somewhat Ä man nered Ä tone Ä ... Ä that Ä ultimately Ä dull s Ä the Ä human Ä tragedy Ä at Ä the Ä story Ä ' s Ä core &lt;/s&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ä It Ä ' s Ä a Ä long Ä way Ä from Ä Orwell Ä ' s Ä dark Ä , Ä intelligent Ä warning Ä cry Ä - L RB - Ä 1984 Ä - RR B - Ä to Ä the Ä empty Ä stud Ä knock about Ä of Ä Equ ilibrium Ä , Ä and Ä what Ä once Ä was Ä conviction Ä is Ä now Ä affect ation Ä . &lt;/s&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>&lt;s&gt; Ä A Ä different Ä and Ä emotionally Ä reserved Ä type Ä of Ä survival Ä story Ä -- Ä a Ä film Ä less Ä about Ä ref ract ing Ä all Ä of Ä World Ä War Ä II Ä through Ä the Ä specific Ä conditions Ä of Ä one Ä man Ä , Ä and Ä more Ä about Ä that Ä man Ä lost Ä in Ä its Ä midst Ä . &lt;/s&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('[CLS] token :', transformer_tokenizer.cls_token)\n",
    "print('[SEP] token :', transformer_tokenizer.sep_token)\n",
    "print('[PAD] token :', transformer_tokenizer.pad_token)\n",
    "databunch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check batch and numericalizer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] id : 0\n",
      "[SEP] id : 2\n",
      "[PAD] id : 1\n",
      "Batch shape :  torch.Size([16, 79])\n",
      "tensor([[    0,   111,   574,  ...,    76,   479,     2],\n",
      "        [    0,    33,     7,  ...,     1,     1,     1],\n",
      "        [    0,   318,    47,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,     5,  2156,  ...,     1,     1,     1],\n",
      "        [    0,    33, 30291,  ...,     1,     1,     1],\n",
      "        [    0, 45518, 10730,  ...,     1,     1,     1]])\n"
     ]
    }
   ],
   "source": [
    "print('[CLS] id :', transformer_tokenizer.cls_token_id)\n",
    "print('[SEP] id :', transformer_tokenizer.sep_token_id)\n",
    "print('[PAD] id :', pad_idx)\n",
    "test_one_batch = databunch.one_batch()[0]\n",
    "print('Batch shape : ',test_one_batch.shape)\n",
    "print(test_one_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom model\n",
    "As mentioned [here](https://github.com/huggingface/transformers#models-always-output-tuples), every model's forward method always outputs a ``tuple`` with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits.Â \n",
    "One way to access them is to create a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our model architecture \n",
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model: PreTrainedModel):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        \n",
    "        #attention_mask = (input_ids!=1).type(input_ids.type()) # Test attention_mask for RoBERTa\n",
    "        \n",
    "        logits = self.transformer(input_ids,\n",
    "                                attention_mask = attention_mask)[0]   \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our transformers adapted to multiclass classification, before loading the pre-trained model, we need to precise the number of labels. To do so, you can modify the config instance or either modify like in [Keita Kurita's article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/) (Section: *Initializing the Learner*) the ``num_labels`` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 473/473 [00:00<00:00, 178200.47B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 5,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = 5\n",
    "config.use_bfloat16 = use_fp16\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501200538/501200538 [00:15<00:00, 32256632.58B/s]\n"
     ]
    }
   ],
   "source": [
    "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
    "# transformer_model = model_class.from_pretrained(pretrained_model_name, num_labels = 5)\n",
    "\n",
    "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LearnerÂ : Custom Optimizer / CustomÂ Metric\n",
    "In ``pytorch-transformers``, HuggingFace had implemented two specific optimizers â€Š-â€Š BertAdam and OpenAIAdam â€Š-â€Š that have been replaced by a single AdamW optimizer.\n",
    "This optimizer matches Pytorch Adam optimizer Api, therefore, it becomes straightforward to integrate it within ``fastai``.\n",
    "It is worth noting that for reproducing BertAdam specific behavior, you have to set ``correct_bias = False``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from transformers import AdamW\n",
    "from functools import partial\n",
    "\n",
    "CustomAdamW = partial(AdamW, correct_bias=False)\n",
    "\n",
    "learner = Learner(databunch, \n",
    "                  custom_transformer_model, \n",
    "                  opt_func = CustomAdamW, \n",
    "                  metrics=[accuracy, error_rate])\n",
    "\n",
    "# Show graph of learner stats and metrics after each epoch.\n",
    "learner.callbacks.append(ShowGraph(learner))\n",
    "\n",
    "# Put learn in FP16 precision mode. --> Seems to not working\n",
    "if use_fp16: learner = learner.to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative Fine-tuning and Gradual unfreezing (Optional)\n",
    "To use **discriminative layer training** and **gradual unfreezing**, ``fastai`` provides one tool that allows to \"split\" the structure model into groups. An instruction to perform that \"split\" is described in the fastai documentation [here](https://docs.fast.ai/basic_train.html#Discriminative-layer-training).\n",
    "\n",
    "Unfortunately,  the model architectures are too different to create a unique generic function that can \"split\" all the model types in a convenient way. Thereby, you will have to implement a custom \"split\" for each different model architecture.\n",
    "\n",
    "For example, if we use the RobBERTa model and that we observe his architecture by making ``print(learner.model)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomTransformerModel(\n",
      "  (transformer): RobertaForSequenceClassification(\n",
      "    (roberta): RobertaModel(\n",
      "      (embeddings): RobertaEmbeddings(\n",
      "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "        (token_type_embeddings): Embedding(1, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (classifier): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(learner.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decide to divide the model in 14 blocksÂ :\n",
    "* 1 Embedding\n",
    "* 12 transformer\n",
    "* 1 classifier\n",
    "\n",
    "In this case, we can split our model in this wayÂ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DistilBERT\n",
    "# list_layers = [learner.model.transformer.distilbert.embeddings,\n",
    "#                learner.model.transformer.distilbert.transformer.layer[0],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[1],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[2],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[3],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[4],\n",
    "#                learner.model.transformer.distilbert.transformer.layer[5],\n",
    "#                learner.model.transformer.pre_classifier]\n",
    "\n",
    "# For roberta-base\n",
    "list_layers = [learner.model.transformer.roberta.embeddings,\n",
    "              learner.model.transformer.roberta.encoder.layer[0],\n",
    "              learner.model.transformer.roberta.encoder.layer[1],\n",
    "              learner.model.transformer.roberta.encoder.layer[2],\n",
    "              learner.model.transformer.roberta.encoder.layer[3],\n",
    "              learner.model.transformer.roberta.encoder.layer[4],\n",
    "              learner.model.transformer.roberta.encoder.layer[5],\n",
    "              learner.model.transformer.roberta.encoder.layer[6],\n",
    "              learner.model.transformer.roberta.encoder.layer[7],\n",
    "              learner.model.transformer.roberta.encoder.layer[8],\n",
    "              learner.model.transformer.roberta.encoder.layer[9],\n",
    "              learner.model.transformer.roberta.encoder.layer[10],\n",
    "              learner.model.transformer.roberta.encoder.layer[11],\n",
    "              learner.model.transformer.roberta.pooler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check groups : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner split in 14 groups\n",
      "[Sequential(\n",
      "  (0): Embedding(50265, 768, padding_idx=1)\n",
      "  (1): Embedding(514, 768, padding_idx=1)\n",
      "  (2): Embedding(1, 768)\n",
      "  (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (4): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (5): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): Dropout(p=0.1, inplace=False)\n",
      "  (7): Linear(in_features=768, out_features=3072, bias=True)\n",
      "  (8): Linear(in_features=3072, out_features=768, bias=True)\n",
      "  (9): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): Dropout(p=0.1, inplace=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (3): Dropout(p=0.1, inplace=False)\n",
      "  (4): Linear(in_features=768, out_features=5, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "learner.split(list_layers)\n",
    "num_groups = len(learner.layer_groups)\n",
    "print('Learner split in',num_groups,'groups')\n",
    "print(learner.layer_groups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I didn't found any document that has studied the influence of **Discriminative Fine-tuning** and **Gradual unfreezing** or even **Slanted Triangular Learning Rates** with transformers. Therefore, using these tools does not guarantee better results. If you found any interesting documents, please let us know in the comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Now we can finally use all the fastai build-in features to train our model. Like the ULMFiT method, we will use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and **gradually unfreeze the model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('untrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('untrain');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we first freeze all the groups but the classifier withÂ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check which layer are trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel\n",
       "======================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "======================================================================\n",
       "Embedding            [79, 768]            38,603,520 False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 768]            394,752    False     \n",
       "______________________________________________________________________\n",
       "Embedding            [79, 768]            768        False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "Dropout              [12, 79, 79]         0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            590,592    False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 3072]           2,362,368  False     \n",
       "______________________________________________________________________\n",
       "Linear               [79, 768]            2,360,064  False     \n",
       "______________________________________________________________________\n",
       "LayerNorm            [79, 768]            1,536      False     \n",
       "______________________________________________________________________\n",
       "Dropout              [79, 768]            0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Tanh                 [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [768]                590,592    True      \n",
       "______________________________________________________________________\n",
       "Dropout              [768]                0          False     \n",
       "______________________________________________________________________\n",
       "Linear               [5]                  3,845      True      \n",
       "______________________________________________________________________\n",
       "\n",
       "Total params: 125,240,069\n",
       "Total trainable params: 1,185,029\n",
       "Total non-trainable params: 124,055,040\n",
       "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
       "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
       "Loss function : FlattenedLoss\n",
       "======================================================================\n",
       "Callbacks functions applied \n",
       "    ShowGraph"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **Slanted Triangular Learning Rates** you have to use the function ``one_cycle``. For more information please check the fastai documentation [here](https://docs.fast.ai/callbacks.one_cycle.html).Â \n",
    "\n",
    "To use our ``one_cycle`` we will need an optimum learning rate. We can find this learning rate by using a learning rate finder which can be called by using ``lr_find``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min numerical gradient: 3.63E-03\n",
      "Min loss divided by 10: 4.37E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot(skip_end=10,suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pick a value a bit before the minimum, where the loss still improves. Here 2x10^-3 seems to be a good value.\n",
    "\n",
    "Next we will use ``fit_one_cycle`` with the chosen learning rate as the maximum learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.051984</td>\n",
       "      <td>0.992576</td>\n",
       "      <td>0.596309</td>\n",
       "      <td>0.403691</td>\n",
       "      <td>05:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VGX2wPHvSYfQezcoSDW0iCgIKB1csKAGy66Vde360zWIDdtiW10VRdd1XRVFxIJKFQUbRYN0EGkBItJ7CQTy/v6YO5M7/U6YZMJ4Ps+Th5k779w5yQzn3nnLuWKMQSmlVHxJiHUASimlok+Tu1JKxSFN7kopFYc0uSulVBzS5K6UUnFIk7tSSsUhTe5KKRWHNLkrpVQc0uSulFJxKClWL5xYsao5o2UzkhIkViEopdRJZ8GCBTuMMbXDtQub3EXkTeACYJsxpm2QNj2BF4BkYIcxpkfYF65ah6mzvqd+1QrhmiqllLKIyAYn7Zx0y7wF9A/xQtWAV4DBxpg2wKVOXhggUfSsXSmlSkPY5G6M+RbYFaLJFcDHxpiNVvttjl9cu2SUUqpURGNA9XSguojMFpEFIvLnKOxTKaXUCYjGgGoS0AnoBVQA5orIPGPMr74NRWQ4MBwgpV4ztNqwUioShYWF5OfnU1BQEOtQSl1aWhqNGjUiOTm5RM+PRnLPxzWIehA4KCLfAu0Av+RujHkdeB0gtX5zo7XklVKRyM/Pp3LlymRkZCBxPGZnjGHnzp3k5+fTtGnTEu0jGt0yk4BzRSRJRCoCZwErnTxRU7tSKhIFBQXUrFkzrhM7gIhQs2bNE/qG4mQq5PtAT6CWiOQDD+Oa8ogxZqwxZqWITAOWAEXAG8aYZU5eXE/clVKRivfE7naiv2fY5G6MGeagzTPAM5G+eJFmd6WUKhUxLT+gqV0pdTLZs2cPr7zySsTPGzhwIHv27CmFiIKLaXIvKtL0rpQ6eQRL7sePHw/5vClTplCtWrXSCiugmNWWUUqpk01OTg5r166lffv2JCcnU6lSJerXr8+iRYtYsWIFF154IZs2baKgoIA77riD4cOHA5CRkUFubi4HDhxgwIABdOvWjTlz5tCwYUMmTZpEhQrRL8MS0+Sufe5KqZIa9flyVmzeF9V9tm5QhYf/1Cbo46NHj2bZsmUsWrSI2bNnM2jQIJYtW+aZrvjmm29So0YNDh8+zJlnnskll1xCzZo1vfaxevVq3n//ff79739z2WWX8dFHH3HVVVdF9feAGCd3ze1KqZNZ586dveahv/jii3zyyScAbNq0idWrV/sl96ZNm9K+fXsAOnXqRF5eXqnEFtvkHssXV0qd1EKdYZeV9PR0z+3Zs2czc+ZM5s6dS8WKFenZs2fAeeqpqame24mJiRw+fLhUYovtgKqeuiulTiKVK1dm//79AR/bu3cv1atXp2LFivzyyy/MmzevjKPzpt0ySinlUM2aNenatStt27alQoUK1K1b1/NY//79GTt2LJmZmbRo0YIuXbrEMFKQWNV3Sa3f3Cxb9DPN61aOyesrpU4+K1eupFWrVrEOo8wE+n1FZIExJivcc3URk1JKxSHtc1dKqTgU2zN3ze1KKVUqNLkrpVQc0m4ZpZSKQzFN7vm7S2fyvlJK/dHFNLnf9O4C9FJ7Sql4ValSJQA2b97M0KFDA7bp2bMnubm5UX/tmCZ3gIkL8mMdglJKlaoGDRowceLEMn3NmCf3xfllW8BeKaVK6r777vOq5/7II48watQoevXqRceOHTnjjDOYNGmS3/Py8vJo27YtAIcPHyY7O5vMzEwuv/zyUqst4+Qaqm8CFwDbjDFtQ7Q7E5gHXG6McXyImrdul9OmSilVbGoObFka3X3WOwMGjA76cHZ2NnfeeSc333wzABMmTGDatGncddddVKlShR07dtClSxcGDx4c9Bqor776KhUrVmTJkiUsWbKEjh07Rvd3sDg5c38L6B+qgYgkAk8B0yMNoFallEifopRSMdGhQwe2bdvG5s2bWbx4MdWrV6d+/frcf//9ZGZm0rt3b3777Te2bt0adB/ffvutp357ZmYmmZmZpRKrkwtkfysiGWGa3QZ8BJwZaQAdm1SP9ClKKRXyDLs0DR06lIkTJ7Jlyxays7MZN24c27dvZ8GCBSQnJ5ORkRGw1K9dsLP6aDrhPncRaQhcBIx10Ha4iOSKiGdo+LjOllFKnUSys7MZP348EydOZOjQoezdu5c6deqQnJzMrFmz2LBhQ8jnd+/enXHjxgGwbNkylixZUipxRmNA9QXgPmNM6CvEAsaY140xWfaKZq99sy4KISilVNlo06YN+/fvp2HDhtSvX58rr7yS3NxcsrKyGDduHC1btgz5/L/97W8cOHCAzMxMnn76aTp37lwqcUajnnsWMN76mlELGCgix4wxn0Zh30opVe4sXVo8kFurVi3mzp0bsN2BAwcA1wWyly1bBkCFChUYP358qcd4wsndGOO5gKCIvAV8EUliP7d5rRMNQSmllA8nUyHfB3oCtUQkH3gYSAYwxoTtZw/n0NGwvTlKKaUi5GS2zDCnOzPGXOO0bWKCa7R4wYbdTp+ilFIYY8pktkmsnWhplpitUG1dv0qsXlopdZJKS0tj586dcV+TyhjDzp07SUtLK/E+YnqB7Ou6NuXNH9az++BRqqe7FjNt2nWIJfl7GZRZP5ahKaXKoUaNGpGfn8/27dtjHUqpS0tLo1GjRiV+fkyT+5rtrpHkDo99Sd7oQQDc+HYuv2zZz98nJvLRzefQsp6e4SulXJKTk2natGn4hiq2hcO+/dX/6PvLlv0AHDx6nP4vfFfWISmlVFyIaXK/9bxmXvcPHjnm12b01F/KKhyllIobMU3u13Vzfb1qXb8Kb36/njYP+9cdG/vNWpb9tresQ1NKqZNaTJN7jfQUqqQlsXb7AZ6Zvipou+/X7CjDqJRS6uQX84t17Cs4xpFjRZzfqk7QNqOn/sKBI8c4drzI0T6X/baX1Vv3RytEpZQ66cQ8uacmuUI4FKC//ZKOxdOA2j48nYc+W+5onxe89D19nv+WAwH2qZRSfwQxT+5/OSfDk+Ddvv6/Hnx/33k8d1k7r+3vzd8Y0b7XbjtwwvEppdTJKObJPTFBOHKsiIopxVPuM2qm06h6xYDti4pCr0wrtHXdHC7849Wt2XuokFVbtEtKqT+6mCf3d+e6CtvPW7fTsy0hIXjdiP22rpavVm7lV5++9b+9+7Pn9h9xGuVlr82l3wvfxjoMpVSMxTy592tbD4CdB4/SrE4lvryru9fjA8+o53W/3agZ3DLOlcCv/18ufZ/3TmQzVxZfu3DRpj0YY/gwdxP7CwpLI/xyZ5V1sDse5huOUiq+xTy5V0lL9tzetq+A5nUrez3+8rCO/PeaMzmtdrpn2+SlvwdMXjOWb/HbdveExdw7cQlnPDLDs23t9gO8/PVqzn36a4a+OoeCAN03v+89XKLfp7w4dFQHk5X6I4t5cu/bpq7n9r4C/4SUkCCc17IOM+/u4bV9z6GjntvuRU4TcvP9nv/Jwt/8tvV67huenfErm3YdJnfDbs59epbnMWMMGTmTOfsfX/PBT5EN4JYnkQ4+K6XiS8yTe/M6lRy1863f/KeXvvfcvuCl7ykqMp4umb92PzWiGLbvP+K5vXzzPs/tj372PzCcLP77Q16sQ1BKxVDMk7t9lkyTGoFnyASyeW+B1/19tj71u/qc7tc+s1HVkPv7+8TFHC8yXGA7aFzcoaHjeOwyciaTkTOZwuNF5O04WKJ9ODVv3c6A8/l3HTzK5j3eXUvb9hWw8vd9fm2VUvEnbHIXkTdFZJuILAvy+JUissT6mSMi7QK1C8Y+x3388C6RPNXLClvSSktOZPLt3bweP3bc1UcfbGHThNx8Trt/ite25ETnx759BYVk5Ez2mvXTfORUej472+ubQTTtKygk+/V5tA1Qk+fo8SLOGf01RUWGbfsLmLVqG73++Q0D/qWVNpX6I3BSz/0t4GXg7SCPrwd6GGN2i8gA4HXgLKcB2Kc9NqhWwenT/Fzx7/le99s08D5TP3LsOO0fncGeQ96zZnq1rMNXv2wLuM9DQebJ/7h+Fy3qVaZqheLB4ExrwDb79Xl+7XcePELtyqnhfwkHHp60jA27DrFu+0Fu7nmaZ7sxhkATZPYfOUbnJ77yjufAEWpWijyehRt3Uyk1yW/Q+2T1jykrWbhxD89nt6fhCXz2lCqPwp6aGmO+BXaFeHyOMcZ9IdR5QMkvHRLGN/f2ZFjnJiHb+E6ldFu7/aBfYq+cmhQ0sQM8+Kn3l5Vlv+1l/Y6DXPbaXNqNmsHOA0fYcSD8WfnmPYfZtq+AvYcLeWb6Lyd0ibD/zd3A7FXb2bjrEDkfL/Vs37ovcCxHjvkfoDo9PjPka/y25zC7Dh71237RK3Po83x8zKE/dPQYr327jh/zdpHz0ZJYh6NU1EW7z/16YGqkT+rQpBp39Goett0pNdM5v2VxgbGW9fzPIFOSnP1K2Wc2Zsbd3WnfuJrfY0sf6eu3bfv+I1zw0vec9+xsz7ZOj88k6/GZfL86dNXK697KpfOTX9Fu1AzGzFpL0xFTOHw0+OrZwuNFAZNyKF3+8RVTl/7ut/1IobNia0VFhp0HjjB/3U66jv6ajo99CcCx40UUFRmvA9JbP6wv1TLMizftYcPO0h2rmL+++HzF/jdavGlPidcI5Obt4s3v159wbEpFQ9SSu4ichyu53xeizXARyRWRXPs1ED+5uWvAQdBA7JUh+7Suy5onBng9fkrN4vnwj13YlpeGdaBaxWR8jb4kk/pVK9Dj9Np+j6XbBnnd/9Hnr9/p187tmemRr4Rt9dA0MnIms2DDLs/0y4ycyUxfvoXmI6fS4oFpEe/zkc9XADDhr2eTdUp1AK9pnnb2sQGAIWN+oNPjMxnp822l2cipnHr/FK8xjUc+X8EFL33Ptn3eg9pO7DxwJOQ3F2MMQ8b8QI9nZnu2FR4v4oOfNpKRM5nt+4/w1cqtLNq0x/P42G/Wev6WTl373588t3/M28XmPYeZuCCfIWN+4IFPl4Z4ZnBDx87l0S9WlOi5Kn7NWbODbfsj/79yoqKS3EUkE3gDGGKMCZoFjTGvG2OyjDFZtWv7J1UnmtQsnlFze6/mJCUmkDd6EK9d3YlZ9/T0ant1l1P4U7sGjBrcJuj+ru2aQb82denTuni+vX0cYOu+AnYfPErFlMSg+zgU4Cy8Zb3K3HZ+swCtvV3y6lyW/VacOP/6zgLP7Uc/L1miqJiSyKm2RV+B+I4NLLXOxNfYiq3Z6/QMevF7fHV+8iu/baHsLyik0+MzeWpa8Nr9vt1BB48co/nIqdz3kSvhnvnETK7/Xy4XjvmBm6y/lbvMxCWvzo0oHrtzRn/NPR8uBuD9HzeVeD/ACXW7qfhijOGKN+Zz8Stzyvy1Tzi5i0gT4GPgamPMryceUmhtGlTlh5zzWf+PgV6zWfq1qUfTWoETmnuOfPWKyVzYvgGLHurjeaxaxRReuzqL167qRIu6lZly+7kAtLOmTp4z+ms6PPYlM1cG75tfHaD65MhBrbjirNDjA25/etk/cQK8+cN6RzXs7x/Y0ut+xZREx9+EQtl7OHzJhtmrgv9dfO084ErcUwJ0H7n5HigDXZ3LbVqAFcnR8lOe828B4P23KnDYFabi37+/WwdA/u6yX/HuZCrk+8BcoIWI5IvI9SJyk4jcZDV5CKgJvCIii0QktxTjBaBhtQp+i5pCaVA1DYC/9jiNF7I7UK1iil+bhARh+l3dad2gCuCqVmnnZMVnfet1ALqeViuiqZTB7Let2g00R71qhWQGtK3vta1iShJ1K6eRHuLbhtuCDbvJyJkc8LF3rKJuodz07oKwbQAe+2IFOR+7Bi437jqEMYbBL3/PG9aH3+23PdH5TxDqoOikzv+lY+d6ylLk7ThIRs5kPv7ZfwW0m30M4t6Ji9npYKBdxb8f1+8O36iUOJktM8wYU98Yk2yMaWSM+Y8xZqwxZqz1+A3GmOrGmPbWT1bphx2ZrIwafHpLV4af63zl6uhLMoM+Vik18AzSZy8tnuKfkCABB3cvbN/AcQyA1wyYuWv9e7z2Hi6kThXvaY1VKiSRkCAsf7Q/E286m0UP9eHc5rUA74VZG3ce4pJXg39d/NdXq73uBxrAdnqW+p/v1zNvXfHZ8P/m5LEkfy+PT15JRs5k7p6wCPDuLvpu9Xa//fjaste/L3Pykt9pNnKqV7+8nX1dwDvXdw66b/fffnG+az93T1gcsA7Rs9NX8dS04nGXL5b8zt0TFoeNXcW/SL8BRlPMV6iWlfaNq4UsJezr9BBzuYOd+XVtVotBmfXp38ZVybJKWjIXd/Re5Xpll1PoHmAQ1/Wa/qUYbnt/IQeOHOPuDxaxxEoyd/ZuTh3bvPnUpESvGT72Vb9ZGTWoVjGFd64/i7zRg7y+TUwO0T0SyLVdMxy1M8Z4Ldz65lf/JP2Iz3jCxwFKPVz9nx/DvtbHC73Ppt+Zt4Fb3nNVDZ269HemLfudw0ePc/SY6yC026dP/9zmwcd+3OWk7QvtWj7oPdC9YMNuXp61hiX53rOHflwfu//UKvaMMazbfsDTXVc5yAlhafrDJPdoyj6zcdDHxlzRkbFXd/Lcd8/GaV2/Chd3bEj7xtW4s3dzaqSncEO3pp52w7ufyoy7etDLmurp7nX6Zct+2j48nY8X/sanizYDcFOP07jR51tI5bRk5o3oxWqf2UO+cgYU98/PX7+TZg5r+wCcfWotFj/kP000I2cyN49b4BlIHP/TJs58Yia/bHF1I/3lzfBJGryLwQXjWwL6gE+xOfvahNe+XcdN7/5Mq4emcfoDrhm69rP5f/+5+EumCHx6S1evrrXr3nL1MP77u8DTG40xQb/5uC8Us3zzXtZsO8DK3/cxbVnpjRGUV298t45ez82OeGpvrCzfvJeXv17N3ycuZtOuQyXez6jPV3D+c9947tes5N8VXNrK/nByEmlep5LfYGne6EFAcbeNu7/63esDL8rt27oeQ9o34O/9W3pWQXZsUp2fH3QN6r5hzYu+f2ArAF6+oiNFxrD3cCHnjP7ab38101NIS07k8s6N2bqvgNt7F68PqGdLTMFUT0/hy7u60+f5b5m9Kny3h13jGq6xjmeGZvL8l7961feZsnQLeTsP0bRWOl9ZBdzmrd3J73ucTwFr/+iXAbf/K7s9d4xfxLvXn8XWfQVMWbqF9o2rsWjTHl6Zvdbx/n3HFtwzpJY80hfBdYCcO6IXm3Yd8kwhLSg8zoIN3v2mRUWGhATxmlkUiDHGb5aR+/PzR7CvoJDHJ68EXN1n9mnK5dUd4xd53tfdhwq9TgAi8dacPK/7eTsPcct7PzPmio4nGqJjeuYewpd392DtkwM996+3nWn78u33dquQksi/sjs4Xt5eISWR9NSkoKUYdlrdClXSknnggtZe9fCdqpQW+Jg+6ZauvHZ1JxY80NuzrXPTGp4uIPcg9qVZjZkzopff848XGZZv3uuZWfTI5yu49q3i+eQjB7biNdu3mmD+6XPt3GZ1KpE3ehDdrHEDgAbVwh/IQklLLv7oV0lLprLt79jYVsDOtxsG4NT7p5CRMzngat3RF58BQKPqFQKuBHayQGrbvgLHF5fZvv8IGTmTS/St4Net+8nImcwLM0tnktvzXxbv94slkXUBxsK+gkKvA/aRY9Gd9TS5jP8GmtzDSEwQTw0Ze5eGr6ISzm0eObAVzwwNPnhbGiokB55F06RGRfq1qUfNSqmsfmIAq58YwAfDuzAn53xWPNrPr/2lnbwrTfywZkfA+fBuN3Y/lQ5NilcEB1tNXCE5kVeuLD7DqZlefOCsbB2YGlT1Pvi9EeEZVqgD9YnItspj5O8OXMLByfTSzk9+xZlPhC4R4eYez7h3YuQDuO6FXC/MXI0xhuNWkbnnZqxy1EUWzlLbOMQz04OvbSgPCo8XeepDuf2wZofftzYnfN93p6vmo02TuwOLH+7rNxjp5h4ELSrhQf7G7qdyaVbgPvxAK2ujwXcq6NNDM3nlyo5UTy/enpyYQHJiAiJCUmKC1yCt21OXZDLS6k4CePiz5WFfu3Jq8e90b98WAdukJicw8Izi6Z3V04uf06d1XZ686Azu6ef93F6t6vDUJWfw84N9ePXK8F99/3J2Rtg2vp4OMYPKqUc/X+6X4PcXFLJw424OHz3Owo2uZOJ0FtKug0esfUR+5S37tNN3523gtPunMPztBbz09RraP/rlCS3GMsYwKLO+37ZA7U7Eis376PjYl4z9Zm3YbjJft773s6errvlI/6opx4uCj6lMXvI7GTmTWR+gpPe787ynEC98sHhdTaDZVqVFk/sJemRwGzJqVgy7IrQkZtiKoKVYB5bLgxwITsRlWY29kqlTCQnCjd1PZdItXcO2ffMa15m1vTvkMtvvclfv4kVXaUmubxbLR/Xjm3t7kppU/E1DRLjirCakJSfSu5Wrz/z5y9shIlx+ZhNqpKcwwMHvUqdKZN06/dvUCzqm8e71Z9GmQRUe/lNrwL9bye7TRZtpN8r7DPG+j5Zw0StzaPXQNC6KcCVj8zqRV+g8dPQYW31KRzw4yXVgtpeZOGxLRM/NWEW3p4rHgIqKDINe/I45a3ZQUHicZvdPYZatCF/TEVMY5TMjasysNYDrzNZdbqPpCO8y25G658PF7Dp4lNFTf6H3P78J/wTLf75f7+kq+jA39Irk57/8lZ83Fp/B/7bnsGdGlr3WlNs/re6osVd1ZNFDfUi3zZTxTfylSZP7CTrntFrMvvc80oJ0dZyIOpXTuLvP6dRMT+H7+85jTs75PHFR26js+xSrjMMDg1qFaRmek9/9/JauRGxffGbv+7/GNs0y1ToApKcmhRyE+1d2e764rRsXdQhdiPTt61xz2ds2dC1Q813R68SIgS2pEGRRWLfmtZh8+7lc29XV1RPJDCRwDUb7ClXuws7eL/xtgCmngVw6di5nBSkdcdS2P/eUX2MML329hvzdh5m0yDVldeqyLSzfvI8r3pjPre8t5FiR4dq3fvIqWeHmXhfy7IxfmbToN4aOjd5SfPvJQiQes9UAundi6Kqg//pqtad8wKJNe+gaYKKDXQtrGnWP0+t4viWf1bSGZ187Dhxh5CdLKSg8jjGGGcu3MG5+9JO+Jvdy7vZezVnwYB/qVEmjQbUKJEVh1SvA6ItdXQyBCqdFqnqE3Ucf33wOs+7pSWKCcG+/Fjx3aTuqVkjmko6uJF0j3Vmt+fTUJNo2DH2FLYDup9fmx5G9+PTmruQ+0JsbuoVfzPandt6LzSqnJXu+PYVjH5z9YHiXgDOp3PPtc4Mscjl09LjX1cWC2W5b5PbnN39k5oqtYZ9jv5RkKIeOuM7c7bOiNux0TQ9MTy0++Lgvbwlw5weL/Loe7OtC7hi/iHXbg1f83HHgSEQVR4/6HEzCVWiF0F0jT150RsjnXjjmB79tvguV6lRJpV3jal4nA+5uxIopiWQ9PpNx8zfywszVzFq1jeHvLGDkJwGvheTl8NHjbNzpfHqmToX8gzr7tJpRm5ZXp0oaF7Zv4JmHD9C1WU127D9Kzxa1/bp8Ojap7rl9y3nFxdUevKAVF7SrH7RGUCQm3dKVIWN+oHEN18BrncquLpVaDi9ScknHhny+2PX7vHZ1J2qkp7Bqy36/dnNyzvfbVs12EZczM2qQkCDMyTnfa2rruPkbeHZG6FkqizftIVGE0+pUom6QbiTfaw7c8HYuy0f1Iy05kcQE4YFPl/LuvI0M7dSIxy9sy38iKEl84MgxVm3ZT78XimcFLfttLw9+uox3gnQvfLNqe8T9/zsOHPG8LzeP+5kf1+9izRMDwp7I/Lp1v1fRPYCr/jOfxQ/39bqQjq9QM4v6tanLxR0bsu9wIRNyN3m9R3eOXxjwOZeOLS5YN2pwG/YVHKOKz4y0MzNcZ+5b9xUfjMd+s5axtp6kjJzJTL3jXFrVrxLwdW56d0HABYHB6Jm7iooXsjvw3d/PY/mofvzzsna8dW1npt/VnREDW9EuQM38QKpVTOG8FnXCN3SgdYMq9G9Tj1euCD/1MpCeLerw8hUdWPRQH/pZK447NKlG71Z1PTNz3rwmK+CUVffA9HktantWRfu2C5fYwTVYeMUb8/26UMINyrV5eDpDx86hoPA4785z1USauCCft+fm+c1aqRxkWizAkvy9XokdYMaKrUETO7gOCDsPFiewt6/rzHd/Py9kvFmPz+S6t37CGONZ2ft8mOmZxhj6BrlwzI3/y8UYw5hZa/xK7e49XMidHywK+Lxpd55LzUqppCUnUqdKGree732NCfvJi/t38/XwZ8tZvGlPwO4pJ25/P/ABBAKv9A5Fk7uKmsY1KpKemsTFHRtFpWjaiUhOTGDs1Z04I8yF0UO5ILOB18yitORE3vhLFr1b1yVv9CDPOEIgeaMH8d9rvf/zT7qlKx/97Zywr/v+ja5rCf9janG9miv+PY+CwuPMXLGVlg9OY/aqbSFnmizcuMdvjv5/f8jza/d/IaqHlnRV6ReLXQOV4244i+6n16ZxjYphE/zXv2zj5a/XeO6PmbWWez9cTEbO5IBTSn3noNu70X7M28WabQd4ZvoqbnvPO1le+9/i1dJ/s12m8su7utOyXuAzZl91KqfyxW3d6Gz1owdir6MUidXbDni6sXo9N9tRwcJgNLkrVUbaNa5GmwaBE0j9qmm8e/1ZDMqsH3AK7Jy1O2n54DRueNtVEuGeD5dEXFr4d1vf+TvXd+b+gS25pmtTVjzaj6/+r4dndpZ7FaXvbJdQ7ulbfJB42ZoVYx8UrhKgm2S2z/UXnvvS+2z9wwWuukHuq4LZ/dmn7tCjPtdseHaG6xuK76ygnzcWl5+4r39LaljfsgJVig1m2/4jtG1YNeREgqcDrF1xOt/9ickrmfDTJtZuP8j9nyxlytLfmRVBaW03Te5KlaFACeH2Xs155/qz6Na8FmOu6OhVqCyYHQeOeOapPzYk+MVogunWrBbDu7vOXCumJHFa7UqcXrcyeaMH0f30Wn7t+7b2/5Zyy3nFZ75VKyT7xWFfG+FbOOuL27qREcF+dGyqAAAS/ElEQVTYSlGR4ckprgqiy37by4/WIOa/stuTN3qQ1xoNgOnLXYO8+2z9/4HKML917ZkM69yYmuklq/0SbEJCn1b+f6/5AVZ1u0286WzP7fd/3Mjfbdf1vXncz56SHpHQ5K5UDF2e1Zi7+5zuNX3y1NrOplK653XPXLmN9f8YGKa1t1DXQ0gPsGDtEduZ8aRburJsVD/usS1CO1x4nKt9FobZz9zdYw+JCcLdfU53NMvJbs/hQl7/1lX7/4KXildBn1qr+G+1+okBXNWliddgqr1Lx14OYp1VViSzUTX+cXFm0IqxDwxqxRCfMt2Tb+/muf2/6zoHnJgQaCyjenoKz1llwWump3BmRvHEgqyM4F08gGfsJBKa3JUqY+5+7r6t6/LkxaGn3gWqoe+rXeNqiAiDgizemjuieEbPqMFtvO4H4pvocga0pEG1Cjw9NJMXh3WgXeNqVEpN8jpALN7kP33Rt+5R3uhBrH1yILf3Kh6ovCzLf43CzLuLF++5E2CgrhmA5rYy2cmJCdRIT2VfQaHfxXZ8OS3/fcO5p/Kv7A6e+6se70+bBuEPTMFm+gxp34BzTqvJS8M6eBbx9WvjOsufeXeP8PuNoGy5JnelythtvZrz08jejLmyY9Ak5L4mwGTrso929ovCQHHXwJU+l3W85bzTeO/Gs6hvq8Pz57NP8brvxHXW4qzLshoz2Gf+/5JH+tKuUVW/mCD0TBy3J6x55fbqi/Z1AsEujANQt0qqXzdX1QrJGONdoC0aS/7dZUbsq6XtljzS16vMQDBJiQm8d2MXzmlWi4s6NOSRP7XmxWGug0ezOpU4r0XodSe/PNbfccw6z12pGKhdOfR8e/s1AZaN6sfoqSs9X819DwedTnGd3Z7TrBbT7jyXO8cv4pct+7mnbwvP2fXih/qy/UBBRJenBNeZc6iBwCppyUy6tZvf9hl3dXd0dpxsXeC+yJaM7QeF7M5NmBWkNLXv5SUh8Mre3/cWeJUJCHRNgnA+ublrwFk7biWpzpqUmMA1Xb0L2I0Y2Mrz+7ZrVJWEBGGhbRA4kkWMTq6h+qaIbBORgEuoxOVFEVkjIktEpOwKFiv1B1ApNYnHLyzuvqkV4sDQsl4Vxt1wFhNvOtsrkVetmEyzCOrQLHigN9Pv7M6HN4WfumnnnukT6kpmgSQkCJdlNXKt7ExO5JbzTuPzW7t51hi4fXtv8ZTKQPO+7RVP3Wf9V70x37OtXeNqVC1BQb701CSvUtClpbrPrJ1Pbu7KX7s7vzyonZMz97eAl4G3gzw+AGhu/ZwFvGr9q5QqBd2b1+KyrEZMyA18we6alVKp6XAlbjAl3ceXd/VwVNY4kKeHFnft3NsvcP0f+zeeQBUZt9imPrasV5ncDbu9ql/WC3LdhWi5PKsxFVNLXmfKPmvH3dc/YmArRIShnRoGe1pAYZO7MeZbEckI0WQI8LZxraiYJyLVRKS+Mab8V+dX6iSy8ME+HCsyiAgrf/cvhVAe1K6cGrbLKVIjB7biiSmuKzrZ67UE6n+2H1h6nF6bXJ967Lf5rDqNtqdO8NoMCQnCqsf7s23fEa9vCqGuJRF0XycUiUtDwF4zM9/appSKourpKZ7E6a5V4p5pEc+yrBkzo31mFgVaM+BedTqkfQNuPb+Z3+ORTsGMhdSkxKh0AUVjQDXQqEnAddEiMhwYDtCkSZNATZRSDowY2JLT6qSTfWb8/z/q0KQ680b0cnSN4CppyUEL4s0LsYgoHkUjuecD9itINAI2B2pojHkdeB0gKyvrxC7BotQfWHJiAleedUqswygz9sRe0mqmTg4O8SQayf0z4FYRGY9rIHWv9rcrpcqD2ff0ZNryLZ51A38kYZO7iLwP9ARqiUg+8DCQDGCMGQtMAQYCa4BDwLWlFaxSSkUio1Y6N/U4LXzDOORktsywMI8b4JaoRaSUUuqEafkBpZSKQ5rclVIqDmlyV0qpOKTJXSml4pAmd6WUikOa3JVSKg5pcldKqTikyV0ppeKQJnellIpDmtyVUioOaXJXSqk4pMldKaXikCZ3pZSKQ5rclVIqDmlyV0qpOKTJXSml4pAmd6WUikOa3JVSKg45Su4i0l9EVonIGhHJCfB4ExGZJSILRWSJiAyMfqhKKaWcCpvcRSQRGAMMAFoDw0SktU+zB4AJxpgOQDbwSrQDVUop5ZyTM/fOwBpjzDpjzFFgPDDEp40Bqli3qwKboxeiUkqpSDlJ7g2BTbb7+dY2u0eAq0QkH5gC3BZoRyIyXERyRSR3+/btJQhXKaWUE06SuwTYZnzuDwPeMsY0AgYC74iI376NMa8bY7KMMVm1a9eOPFqllFKOOEnu+UBj2/1G+He7XA9MADDGzAXSgFrRCFAppVTknCT3n4DmItJURFJwDZh+5tNmI9ALQERa4Uru2u+ilFIxEja5G2OOAbcC04GVuGbFLBeRR0VksNXs/4AbRWQx8D5wjTHGt+tGKaVUGUly0sgYMwXXQKl920O22yuArtENTSmlVEnpClWllIpDmtyVUioOaXJXSqk4pMldKaXikCZ3pZSKQ5rclVIqDmlyV0qpOKTJXSml4pAmd6WUikOa3JVSKg5pcldKqTikyV0ppeKQJnellIpDmtyVUioOaXJXSqk4pMldKaXikCZ3pZSKQ46Su4j0F5FVIrJGRHKCtLlMRFaIyHIReS+6YSqllIpE2MvsiUgiMAboA+QDP4nIZ9al9dxtmgMjgK7GmN0iUqe0AlZKKRWekzP3zsAaY8w6Y8xRYDwwxKfNjcAYY8xuAGPMtuiGqZRSKhJOkntDYJPtfr61ze504HQR+UFE5olI/2gFqJRSKnJhu2UACbDNBNhPc6An0Aj4TkTaGmP2eO1IZDgwHKBJkyYRB6uUUsoZJ2fu+UBj2/1GwOYAbSYZYwqNMeuBVbiSvRdjzOvGmCxjTFbt2rVLGrNSSqkwnCT3n4DmItJURFKAbOAznzafAucBiEgtXN0066IZqFJKKefCJndjzDHgVmA6sBKYYIxZLiKPishgq9l0YKeIrABmAfcaY3aWVtBKKaVCE2N8u8/LRlZWlsnNzY3Jayul1MlKRBYYY7LCtdMVqkopFYc0uSulVBzS5K6UUnFIk7tSSsUhTe5KKRWHNLkrpVQc0uSulFJxSJO7UkrFIU3uSikVhzS5K6VUHNLkrpRScUiTu1JKxSFN7kopFYc0uSulVBzS5K6UUnFIk7tSSsUhTe5KKRWHNLkrpVQccpTcRaS/iKwSkTUikhOi3VARMSIS9hJQSimlSk/Y5C4iicAYYADQGhgmIq0DtKsM3A7Mj3aQSimlIuPkzL0zsMYYs84YcxQYDwwJ0O4x4GmgIIrxKaWUKgEnyb0hsMl2P9/a5iEiHYDGxpgvohibUkqpEnKS3CXANuN5UCQBeB74v7A7EhkuIrkikrt9+3bnUSqllIqIk+SeDzS23W8EbLbdrwy0BWaLSB7QBfgs0KCqMeZ1Y0yWMSardu3aJY9aKaVUSE6S+09AcxFpKiIpQDbwmftBY8xeY0wtY0yGMSYDmAcMNsbklkrESimlwgqb3I0xx4BbgenASmCCMWa5iDwqIoNLO0CllFKRS3LSyBgzBZjis+2hIG17nnhYSimlToSuUFVKqTikyV0ppeKQJnellIpDmtyVUioOaXJXSqk4pMldKaXikCZ3pZSKQ5rclVIqDmlyV0qpOKTJXSml4pAmd6WUikOa3JVSKg5pcldKqTikyV0ppeKQJnellIpDmtyVUioOaXJXSqk4pMldKaXikKPkLiL9RWSViKwRkZwAj98tIitEZImIfCUip0Q/VKWUUk6FTe4ikgiMAQYArYFhItLap9lCIMsYkwlMBJ6OdqBKKaWcc3Lm3hlYY4xZZ4w5CowHhtgbGGNmGWMOWXfnAY2iG6ZSSqlIOEnuDYFNtvv51rZgrgemBnpARIaLSK6I5G7fvt15lEoppSLiJLlLgG0mYEORq4As4JlAjxtjXjfGZBljsmrXru08SqWUUhFJctAmH2hsu98I2OzbSER6AyOBHsaYI9EJTymlVEk4OXP/CWguIk1FJAXIBj6zNxCRDsBrwGBjzLboh6mUUioSYZO7MeYYcCswHVgJTDDGLBeRR0VksNXsGaAS8KGILBKRz4LsTimlVBlw0i2DMWYKMMVn20O2272jHJdSSqkToCtUlVIqDmlyV0qpOKTJXSml4pAmd6WUikOa3JVSKg5pcldKqTikyV0ppeKQJnellIpDmtyVUioOaXJXSqk4pMldKaXikCZ3pZSKQ5rclVIqDmlyV0qpOKTJXSml4pAmd6WUikOa3JVSKg45Su4i0l9EVonIGhHJCfB4qoh8YD0+X0Qyoh2oUkop58ImdxFJBMYAA4DWwDARae3T7HpgtzGmGfA88FS0A1VKKeWckzP3zsAaY8w6Y8xRYDwwxKfNEOB/1u2JQC8RkeiFqZRSKhJOkntDYJPtfr61LWAbY8wxYC9QMxoBKqWUilySgzaBzsBNCdogIsOB4dbdIyKyzMHrl7VawI5YBxFAeY0Lym9sGldkNK7IxCquU5w0cpLc84HGtvuNgM1B2uSLSBJQFdjluyNjzOvA6wAikmuMyXISZFnSuCJXXmPTuCKjcUWmvMbl5qRb5ieguYg0FZEUIBv4zKfNZ8BfrNtDga+NMX5n7koppcpG2DN3Y8wxEbkVmA4kAm8aY5aLyKNArjHmM+A/wDsisgbXGXt2aQatlFIqNCfdMhhjpgBTfLY9ZLtdAFwa4Wu/HmH7sqJxRa68xqZxRUbjikx5jQsA0d4TpZSKP1p+QCml4lBMknu4cgal8Hpvisg2+9RLEakhIl+KyGrr3+rWdhGRF63YlohIR9tz/mK1Xy0ifwn0WhHG1VhEZonIShFZLiJ3lIfYRCRNRH4UkcVWXKOs7U2t8hKrrXITKdb2oOUnRGSEtX2ViPQ7kbhs+0wUkYUi8kV5iUtE8kRkqYgsEpFca1t5+IxVE5GJIvKL9Tk7O9ZxiUgL6+/k/tknInfGOi5rf3dZn/llIvK+9X8h5p+vEjHGlOkPrkHZtcCpQAqwGGhdyq/ZHegILLNtexrIsW7nAE9ZtwcCU3HN3e8CzLe21wDWWf9Wt25XP8G46gMdrduVgV9xlXiIaWzW/itZt5OB+dbrTQCyre1jgb9Zt28Gxlq3s4EPrNutrfc3FWhqve+JUXg/7wbeA76w7sc8LiAPqOWzrTx8xv4H3GDdTgGqlYe4bPElAltwzd2O9ee+IbAeqGD7XF1THj5fJfp9yvwF4Wxguu3+CGBEGbxuBt7JfRVQ37pdH1hl3X4NGObbDhgGvGbb7tUuSjFOAvqUp9iAisDPwFm4Fmwk+b6PuGZSnW3dTrLaie97a293AvE0Ar4Czge+sF6nPMSVh39yj+n7CFTBlaykPMXlE0tf4IfyEBfFK+1rWJ+XL4B+5eHzVZKfWHTLOClnUBbqGmN+B7D+rWNtDxZfqcZtfaXrgOssOeaxWV0fi4BtwJe4zj72GFd5Cd/XCFZ+ojT+Zi8AfweKrPs1y0lcBpghIgvEtRIbYv8+ngpsB/5rdWO9ISLp5SAuu2zgfet2TOMyxvwGPAtsBH7H9XlZQPn4fEUsFsndUamCGAoWX6nFLSKVgI+AO40x+8pDbMaY48aY9rjOlDsDrUK8RpnEJSIXANuMMQvsm2Mdl6WrMaYjruqpt4hI9xBtyyquJFzdka8aYzoAB3F1d8Q6LteLufquBwMfhmtaFnFZffxDcHWlNADScb2fwV6jzHNFJGKR3J2UMygLW0WkPoD17zZre7D4SiVuEUnGldjHGWM+Lk+xARhj9gCzcfV1VhNXeQnf1/C8vniXn4h2XF2BwSKSh6s66fm4zuRjHRfGmM3Wv9uAT3AdEGP9PuYD+caY+db9ibiSfazjchsA/GyM2Wrdj3VcvYH1xpjtxphC4GPgHMrB56skYpHcnZQzKAv2kgl/wdXf7d7+Z2uEvguw1/qKOB3oKyLVrSN8X2tbiYmI4Frdu9IY88/yEpuI1BaRatbtCrg+9CuBWbjKSwSKK1D5ic+AbGtWQVOgOfBjSeMyxowwxjQyxmTg+tx8bYy5MtZxiUi6iFR238b1919GjN9HY8wWYJOItLA29QJWxDoum2EUd8m4Xz+WcW0EuohIRev/pvvvFdPPV4mVdSe/NcAwENfMkLXAyDJ4vfdx9aEV4jqqXo+rb+wrYLX1bw2rreC6OMlaYCmQZdvPdcAa6+faKMTVDdfXtSXAIutnYKxjAzKBhVZcy4CHrO2n4vqQrsH1VTrV2p5m3V9jPX6qbV8jrXhXAQOi+J72pHi2TEzjsl5/sfWz3P2ZjvX7aO2vPZBrvZef4ppVUh7iqgjsBKratpWHuEYBv1if+3dwzXgpN5/7SH50hapSSsUhXaGqlFJxSJO7UkrFIU3uSikVhzS5K6VUHNLkrpRScUiTu1JKxSFN7kopFYc0uSulVBz6f3aekh9qlaQ8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('first_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('first_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then unfreeze the second group of layers and repeat the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we use slice to create separate learning rate for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.912813</td>\n",
       "      <td>0.906528</td>\n",
       "      <td>0.631616</td>\n",
       "      <td>0.368384</td>\n",
       "      <td>06:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VGXWwPHfSYEQCL0TIKFIkW5oYkFEpShYWAV1X+uytlUs+xqsyKKi6667vnZ27ZRlwYJSBUFUeieASIsQAQm9BhLyvH/MncmdmTstJEwYz/fz4cPMnWfuPclMzn3u064YY1BKKRVb4qIdgFJKqZKnyV0ppWKQJnellIpBmtyVUioGaXJXSqkYpMldKaVikCZ3pZSKQZrclVIqBmlyV0qpGJQQrQPHJ1cxHVo1RyRaESil1Lln+fLle40xtUKVi1pyT6hSm/kLFlGxfNRCUEqpc46I/BxOuag2y2itXSmlSkd0kzua3ZVSqjRENbkbdEVKpZQqDVFt8NbVhpVSkcjPzycnJ4e8vLxoh1LqkpKSSE1NJTExsVjvj25yj+bBlVLnnJycHFJSUkhLS0NiuNPOGMO+ffvIyckhPT29WPuIbrOMVt2VUhHIy8ujRo0aMZ3YAUSEGjVqnNEVSpTb3JVSKjKxntjdzvTnjHLNPZpHV0qp2BXd5Qc0uSulziEHDx7kzTffjPh9/fr14+DBg6UQUWA6FFIppcIUKLmfPn066PumTZtG1apVSyssRzoUUimlwpSZmcmWLVvo0KEDiYmJVKpUiXr16rFq1SrWr1/Ptddey44dO8jLy+Ohhx5i6NChAKSlpbFs2TKOHj1K3759ueiii1iwYAENGjTgiy++oEKFCiUea8jkLiLvAVcDe4wxbYKU6wwsAm4yxkwK5+Ca25VSxfXcl+tYv/Nwie6zdf3KPHvN+QFfHz16NFlZWaxatYp58+bRv39/srKyPMMV33vvPapXr86JEyfo3LkzN9xwAzVq1PDax6ZNmxg/fjxjxozhxhtvZPLkydx6660l+nNAeM0yHwB9ghUQkXjgJWBmJAfXoZBKqXNZly5dvMahv/baa7Rv355u3bqxY8cONm3a5Pee9PR0OnToAMAFF1xAdnZ2qcQWsuZujJkvImkhiv0JmAx0juTgmtqVUsUVrIZ9tlSsWNHzeN68ecyePZuFCxeSnJxMz549Hceply9f3vM4Pj6eEydOlEpsZ9yhKiINgOuAtyN9r1bclVLnkpSUFI4cOeL42qFDh6hWrRrJycn8+OOPLFq06CxH560kOlT/ATxujDkdatC9iAwFhgKUq9tMR8sopc4pNWrUoEePHrRp04YKFSpQp04dz2t9+vTh7bffpl27drRo0YJu3bpFMVKQcNq9rWaZr5w6VEVkG3jW7q0JHAeGGmM+D7bP8vWamx0b11K7clKkMSulfqM2bNhAq1atoh3GWeP084rIcmNMRqj3nnHN3Rjj6U0QkQ9wnQSCJnbPe8/04EoppRyFMxRyPNATqCkiOcCzQCKAMSbidnY7bXNXSqnSEc5omSHh7swYc3skB9c2d6WUKh26cJhSSsUgXfJXKaVikN6sQymlYpA2yyilVCmpVKkSADt37mTQoEGOZXr27MmyZctK/NhRTe7fbdobzcMrpdRZUb9+fSZNCms9xRIT1SV/9x09Gc3DK6VURB5//HEaN27MfffdB8CIESMQEebPn8+BAwfIz89n1KhRDBw40Ot92dnZXH311WRlZXHixAnuuOMO1q9fT6tWrUptbZmoJvffyK0QlVKlYXom7F5bsvus2xb6jg748uDBgxk2bJgnuU+cOJEZM2bw8MMPU7lyZfbu3Uu3bt0YMGBAwHugvvXWWyQnJ7NmzRrWrFlDp06dSvZnsEQ1ucfHRfcuf0opFYmOHTuyZ88edu7cSW5uLtWqVaNevXo8/PDDzJ8/n7i4OH755Rd+/fVX6tat67iP+fPn8+CDDwLQrl072rVrVyqxRjW5d29aI3QhpZRyEqSGXZoGDRrEpEmT2L17N4MHD2bs2LHk5uayfPlyEhMTSUtLc1zq1y7UIoslQavOSikVgcGDBzNhwgQmTZrEoEGDOHToELVr1yYxMZG5c+fy888/B33/JZdcwtixYwHIyspizZo1pRJnVGvuhToWUil1jjn//PM5cuQIDRo0oF69etxyyy1cc801ZGRk0KFDB1q2bBn0/ffeey933HEH7dq1o0OHDnTp0qVU4tQbZCulVITWri3qyK1ZsyYLFy50LHf06FHAdYPsrKwsACpUqMCECRNKPcYoN8todldKqdKgM1SVUioG6cJhSqlzym9lTaoz/Tl1tIxS6pyRlJTEvn37Yj7BG2PYt28fSUnFvw1pVDtU8/JPR/PwSqlzTGpqKjk5OeTm5kY7lFKXlJREampqsd8f1eT+15kbubh5rWiGoJQ6hyQmJpKenh66oIpus0zuEV04TCmlSkNUk3ucrhymlFKlImRyF5H3RGSPiGQFeP0WEVlj/VsgIu3DPfhFzWpGEqtSSqkwhVNz/wDoE+T1bcClxph2wF+Ad8M9eOf06uEWVUopFYGQHarGmPkikhbk9QW2p4uAsLt3dW0ZpZQqHSXd5n4XMD3cwoWFmtyVUqo0lNhQSBG5DFdyvyhImaHAUIBydZuhuV0ppUpHidTcRaQd8C9goDFmX6Byxph3jTEZxpgM0GYZpZQqLWec3EWkEfAp8HtjzE+RvFeTu1JKlY6QzTIiMh7oCdQUkRzgWSARwBjzNvAMUAN407p1VIG7Zh6KtrkrpVTpCGe0zJAQr98N3F2cg5/W3K6UUqUiyuu5a3ZXSqnSENXkrm3uSilVOqKa3F+Y9mM0D6+UUjFLb9ahlFIxKOrJ/YtVv0Q7BKWUijlRT+4PTVgV7RCUUirmRD25K6WUKnllKrkXFhomLc9h71G9Q9PUNbuYvf7XaIehlDpHlank3vn52Tz239Xc/v4SjDFMX7uLkwUlcxPtORt+5dCJfB7772rSMqeW2Ztz7z92ipXbD3D/uBXc/dGyaIejlDpHRfUG2QCp1SoAcLLgNPuOnQIg65fDLNiyj3vHrmDoJU14ol+rMzrG/J9yuetD70T55eqd/C6jIZ8s+pkODavSpkGVMzpGSThx6jSd/vJ1ie3PGIPorQyV+k2KWs29We1KACTGu0LYc9i7KearNbsAyN577IyPdTgv32/bnyetAeCpz7O45vXvAdi4+wg5B46f8fGKa9h/VpbYvr7ftJf04dPYmnu0xPZ5pmat283uQ3nRDkOp34SoJfcKifEAbLOS99Ls/V6vj1+yHYAfdx8542M9MM45aR49WQCAMVBwupCr/jGfi16a61XGGMOL0zewYdfhM44jlJnr/NvYD53wPzGF49Z/LwZgTc6hM4qpJGz69QhpmVMZ+vFybnhrQeg3KKXOWJloc885cJxHJq52fG37/uOltgbNw/8pGobZ7MmiG0idKij0tMkfOpHPO99u5ZZ/LS6VGLbmHmVG1q6Ar09cuuOM9m+I/hIPc37c43n8y8ETUYxEqd+OMpHc7bXllCT/boAx323l5jGLyBj1dYkm+pMFhY7br3z1W1o+PQOA46dcSX6/1R9Q0nr97Vvu+WQFJ045d/AeO1VwRvsvC8v3jJ6uy0wodbaVieRuN+7ubn7bXpj2Iwu27GPv0VOkD5/Gtr3HWLjF+4ZPK7cfoP1zs9hpqxlOX7uLtMypAY/VpGZFx+3Z+1zt7mmZU/nGVussTa2emeG4/R+zN3k9/2LVL2zeE35TVYGuma/Ub1JUk/un913ot6125fIh33fZK/MYMmYRcza42qhXbD/AdW8u4NCJfHr+dR4Aefmneey/RU09V7er53nsHkDyyaKfQx7rqc+zACiX4P+rOnj8FE98tpbjpwpYuGUfGaNmc8Sh8zaQSIdjFhYaHpqwiqv/7/ug5ebaTkiHjhevzV4pdW6LanLv1Kia1/PP7+9BjYrlwn7/XR8uY9veYwx+d5Fn26nTrqaWlk/P4JitqaNqcqLn8frn+gD+tdrW9SoHPNapgkL+/f02r223/nsx4xZvZ/LyHEZP38DeoyfD6gC+7JV5pGVO5bb3lvi99s/BHZgx7GK2vNDP77VPFrtORnn5hQGbcY6eLOCOD5Z6nj8/bUPIeCKVljmVF6cXf78Fp52bw8KxYvsBFmzZW+z3K/VbUaaaZc6rU4mE+MhCuuyVeZyytZ1f36mBY7lqyUUnjQrl4h3LdGxUNeix/j5rIwD7jp7kSF4+Wb+4RtAcOVnA6ghGpbhHCC3ett/vte5Na9CybmXi44rGp2+0ThjPfLHOs+2+sctJy5zKiVOn+X7TXs/JYtxi/6uRXYdKrhPztHVCfOfbrXzww7agZY+fKvBqFnN/NsXtvyg4Xcj1by7g5jGl07kdSw6dyCctcyrLfz7g+PqxkwW8OG2D5/NUsSfqyf38+kW15eRyrs7UV29qD8CMYRdHvD9jYMFm/5pdlQqJjL6+LUO6NHR835cPXMRFzWp6nmc9d5VfmfxCw4UvzuGCUbNpO2KWZ/vLMzZ6Hj8/dQMHjwdOXk4dwlMe6OF5XLFcUYdyJ+tks/twnifBu83dmAvAX6au544PXFcA3/6U67hG/oFjrqaZv8/aSLsRMwN2SjcZPpWRX67np1+drz72Hzvl1ZQ04sv1jLVOJt/+lMsyn+GsX6za6Xl8bYf6XNGqDgBjF2933H8o949bUaz3/Ra1f871/Qw09LTdc7N4Z/5W3p2/9WyGpc6iqCd3d55pZWsSua5jKtmj+9OybuBmkkC27T3GzQ7DFtfvPMzgLo148fp2fq9lj+5P29QqXGgl92G9m1OpvP+onVMFhewMMQln1Y6DdBjpPcvUGONpi3ePrbdrl1qV2Y9cyqhr21DRdlz7zNwRU9b5vQ9g3OLtVE5KdHzNbcOuw7w1bwuvfbOZw3kFbLWuHA4dz/ck6xvfWUihgfd+2MaVr85n5rrdXv0HJwtcs2cfn7zGa99PfpbFRwuzue29JQx6e6HXa+7ZxwCPXdWCKlbT2D/nbGLznqO8OG1DwBPNF6t+IS1zKhe99I3nRur2eQCbApyAziV7juTxzBdZXleekcrLPx1y4p3T79hdY6+dErqPS52bQiZ3EXlPRPaISFaA10VEXhORzSKyRkQ6RRJA1ybVAfi/IR0dX5/9yKWex22DLBEwuLOrRr5qx0HH13u2rO31vG7lJL8yVSokkj26P8N6nwfAiGtaAzBz2CUBjxuI/Q9qzHdbaTtiFltyjwZsk29WuxK3dmvstc3dT/DWvM0s3LrP6W30Ob+uZ9kGuzdu7sSDvZoB8Oh/V/Ov74pqaGtyXL+j9iNn0fLpGaRlTmWJTxPRHz9eTtsRs3h+6nryTxcyfPJaoGjmsJ29uWhG1m6++dGVhI/ZTmQNqlbwGpbZ++/f8s78rQFPlu6loHMOnKDJE9N48rO1Xq+P+S68Guf0tbtYtzN6E7lOFRSSljmVS172nhy3be8xnvosi48W/uz5fRXHQxNWctFLcx0rDW6H87xfszfTHT/DobbK9T3/aGF2mbsndDhry3wAvA58FOD1vkBz619X4C3r/7AMu/w8OjSsStNazsMS3csUADx65Xnc+cFSlj11BZ+uyGHUVFenXr+2dXn+urZM8JnwM/neCz2XpdfYRssAfPPYpXy5eicD2ju30QP8T/c0+rWtR22HE0Eo6cOn+W17aMJKTzt9ONz9BIu2+rfNu81Yt9txe4u6KXRrUp3XvtkM4HUC+GzlTo7khfdHPea7bYz5Lnjbut09nywHYMsL/bjnk6JmFBEhzWHo6enT4f1B+DbltE0N3j/idu9YVwzZo/uHVb4kGWO41/p9bN9/nLx81/pJ1ZPLcdkr8zzl7vlkRcTx5eWf9szFAPhoYTb39WzGrkMnGOfzu9qae5SOtsEL9qU+DpbQaKpTBYWOI8rOlmiuo3T+szMBWLJtP6/fHFHdtlSF/DSMMfOBwNkFBgIfGZdFQFURqRekvJcqyYkM7NAg6AfzVP9WfHhnF3q2qM3WF/tTvWI5KlcoaooYMeB8rw5It06NqvLTqL5sGNnHb//J5RK4qXOjgJ2rAHFxElFif9aq6QdiT+yJ8aG/iFUq+De39LbarYN55/cX0Kx2JWpUKk/lpAS/q5T5P+V61bZLw8szi9r+m1gn7gZVK/h1Wh/P9z7JfLVmZ9A+C7enP3e8kAwoUK1qafZ+xz4at7TMqaRlTg0rJl/pw6d5zc59ZeZGeoz+hm9/yvUrWxhhx6bvWkzx1vc7c/Ja/s86obv/JtydqketGqZ9qY+DxVzewu6NuZs576npjj/X2TBm/lbSh09j7sazMyclEKer2pLw4+7DpGVO5dWvf4rofSVxqm0A2KvMOdY2PyIyVESWiciy3Nzwvwh3X9yES8+r5bVtQPv6XNy8JuP+0JXaKa7k9dGdXXyPR7mEuKAJPFz39WzquH1w54bUr+I6vm+MwQzp0ihkGaeRQ/+6LcPzuM/5dT2Ph/Vuzmf3Xcg/B3fgKtv29JoV2X04vMW6HrniPMcZwsXxzrdFzSbv/v4Cz+PrOnp/Nfr84zvP45XbD/DAuJV+fRZ2PVuE/zu2O+YwdDQv/zS/e3shN/9rMfuOnmTUV+v59qdcOo6cxYlTp72ac97/ITvo/k8XGvYcKfo95zsM9/yXNZQ289M1fq/lOSxtvWN/4Lb0vce8k7v7Km/xtqLmO/fvetTUDaRlTuW5Ket45ot1niteKP7aRXZ/nekaUBCtRercw33veH8p328Kb5jssZMFjJiyjmMnC3j/h21+a1uFK9hnVBIyJ6/x/I38c86mEKW9lURyd6qCOlZDjDHvGmMyjDEZtWoV74/ULSkxno/v6sqFTYtGuFzYtIbnccu6KWe0f1//26clAB0aVmXoJU0A1x/P89e15bvHezHn0UtpUqtSsF14uaK1qwbeo1mNoOUet45r16Cqq6OyZkrR8M6jeQV0bFSNgR28k2ckQzTv7dmUtSP8Rwm52S+O7rooPax9PtGvJc1qF30WiUGGul73pvfIjo6NqjL2bu8WvitbF524Dh4/FbTGax9yaV9d1BjDxKU7vJo1Lhg1m399v43b3lvCgeP5nP/sDPq/VjRZ7J9zNpGWOZWPHSa+HT1ZQNMnptHl+TmeG80ESzJOTSGtn5nJIxOL1jqasnonF788l8HvLiQtc6rfrOTcI97J/dCJfIwx5OUXnVR8E89/l+d4Pa9fJalYzTIHjp2i1dMzOODT1xPss41EYaFh+KdrGfLuIoZNWBl0YqBvDO4F80IZ891WPliQzfnPzuS5L9fzu7cXFqvN3L4wXyRzdMLl29QciZL4NHIA+/jCVGBngLKlyl7Tvamz85DHM7HqmSuYdE937roonQ4NqzKsd3Pi44T4OKGpldh9k1Egza2EN7hz8Bq8PYlufr4vANOHXcySJy9n+/6ijrF7AlxZ2N3aLfCxPr6rS8g/zkIDW1/ox9zHevL01a1Z/lTvkMcceol3XE4jQ578bK1fsgJYuf0gPWzDU1vXq8yQLg09k806jPyaV2f7X6q+NW8LaZlTWZ1T1LnuntU7ZfVO0odP438n+9ee7QKdM9773r//oY3V5gqw9+hJ9hzJ85pIFq5PVxTdLH6W1Zfi7m+ZuMw7Mf/g05R08MQpv99hnzZ1CaZh9WQOnQje3LR+52G/k0THv3zNifzT3P6+9yS8Kat28vHCbNIyp/Kr7WrRGBPRFcLWvccYv2Q7C7fu4/NVO5nsc1Kye2XWxoCvBWOf9+KWPnxaxEuM24cNu/u13J3owZY+ORtKIrlPAf7HGjXTDThkjCmdxqcI3H5hWonvs2pyORLi46hTOYnP7+9B4xr+HYQ9mtUke3R/pj54EeP+0JWbMhqSPbo/b9/qapq4vGVtlj3Vm7pVksge3Z9r2tcPesxyCXFMeaAH4+7u6jl5VU5KpHZKEvNtbZxOX1aAL+4vGkNvr/X6ckq6f7+xvVdfxrPXtCYuTki3OkZrVCrPxD92D7jPux1q9zd3bcSt3Rp5zWEYu3g7nZ+f7Vf2dxekAq4+F4DkcvGIiNcV2vgl/jWbl2a42vv/+PFy73g+XMqD489szXz3r+P4qQIKC41fO3Off3xHl+fnFHv/7iGKvu23vn1KHy30voI4eDyfLi8UHffGjFR+7zP6yldKUqJjx7p7iea0zKn0e+07LvYZ6eO2OucQK7cXTZJakr2fp62+nK4vzPFM1ntn/lbaPzeLPYfzWJNz0DPBarE1AuzKV78lY9RsT5uy73yJkV+tD/gzuDva/zrINcTZPvx2a+5RXv/GdcU14HXvJTsSAvR5RdJub4zxNJW4J+jlny7kvKemB3tbSC2fnk5a5lQW+YyQi7TJNJyhkOOBhUALEckRkbtE5B4RuccqMg3YCmwGxgD3RRRBCXP/EUT7DkTn16/ChU1r8pL1pevTpi7Zo/vz79s7U7NSZGOL26VW9YzBD8SpQxmgfcOq3NkjnUrlE+je1LsJyL7ejv2q58M7u3Brt0Zc3ymVl28omhdwfcdUv/13Sa/ueTzpnu589aeLPPu962L/5J4YH8eoa9vSsm5l5jx6qd/rdi9bvzt3H8Kd1slii61tN9j9dn1PWLM3RN7hViulPOfVKWpuO3XatRx062dm8tKMHx2XkLjQ5/dsH/Hl9tWfLnI83qodBx1vLbnX4crGznc00cuD2gec7f3No5ey9YV+VCof71n11M63+QaKhs/68m1Ks7vslXkcO1ngmcw2dvF2Brz+g2eC1U3vLiItcyo//XqUvUdPehKl7xVksL7mxjWSAVel6rbujTlsu0K47f0lvDLrJyv+Q545Hf1f+44nP3PukN+8J/x+g+ttE8TEap32/T4U5zah7qY136a9I3kFEQ1dDWe0zBBjTD1jTKIxJtUY829jzNvGmLet140x5n5jTFNjTFtjTFRv/Ln4ictZNPzyaIZw1rx/e+ewyj1zTWuynruKxPg4r8lilzSvxeR7u5NesyJd0oqS9KXn1WLUtW0B79pClWTnyVLZo/uTPbo/GWnVadOgCi/d0I7J915IvSoVHMu7Na6eHPR19wm6YfVkskf3p19b10mjbhXv0T8TlngntvIlOCRv6ZO9mfJAUSJuULWC5/L7/QXZju9ZYFux9OUb2jHu7q58/bD3XIk2Daqw9Mnefovn3fDWAm54a4HfCcEp4QJen1u4mtSqRFyckFw+wTFZrNrun8gHvP6D53FajeCfm93BE/meG91MD3LfAjdjDMkOAyCc2sPv/nAZP+87Tmq1CtSvWoEqyeU4nFdA/ulCCgsNO/Z7L7vh7mNZtzPwcOQjeQXsPXqSrF8O0erpGXy5uqiFOS//NAu27PV0lq+0/Z5qWZPBFvisVvvT7sAnC1cfiXfyty8H8frczX7v+Z3PRMFgoj5DtaTVrFTe748/Vl3WsjYpSQleCTuU6Q9dTPbo/iwc3osbOzfkgsbVmftYz4AjilJCzH51UrF8Ahc0rhayXEJ8nGekka+r2wUeTduxofe+Mz9dy/5jpzy3Uwy0Tr8T3xOk03jzpMSi382irfv5fKWrbTycmaXXtK9P7cpJNK+TQvbo/vzjpg5Mf8jVJFUrpTydGlVDBK/fQ9Yvhx37P9xt6u4JSxc2rcHEewI3i4FraYv373CuBFQsF8+xk6eZkbWLXq/M8ySWJUFGjpwqKPQsiR0O+/pDP/0aula8/OcDrHe461n68GlMW7uL6978gZlWf8Rsa1XYnAMnrP9dcd37yXKv/pZwuCdBJpeLJ2PUbK7+v+85kX+aP41fyeV/mwfAsAmruHnMYpo/OZ1HJ64mw/qOD2hfn2G9mzvu95rXA6/gOua7rbR8eobX8uX2Kw+n2cPBTky+Yi65/9asHXGVJ1lEIlSt2q207+S0YPjlPHBZM8/zp69uzZQHevDPwc4zlgGuc1gcrtNfvqbdiFncN3a532vv397Zrzb4RL+W1tWG/0moXaprJrS9z+CHzF6ex+6hfy3rptC8diVa1avM+pHOo4x8T5rXdmzgdzLe9mJ/pvl8hht2HaZDQ+85AW9/uwWA41Zyd1/JPDfgfE+ZYb2b8/3jl9l+lqpc1sJ7drZbcrkETuSf5p5PVrB17zFPp2fNSoFHfbjb2Dv7/N76t3U+GQebAOc0cfGVWRs94/Tv9RkkcN/YFazcfpA/frzccdSSe+TP7A172B5giGJbW+e33YvXu65UnUanbMl19R3YJwxOXpFDy3quQRF/ubaNVwUA4GFrlruTHfuPk5Y51bMO1JAxizxLc++3zac4dCKfcvFx3NezKYufiLw1QpO7Cuq8Oq4vcEmNf3diHxPesFoF2qVWDdiHAK422XdsY+cB6lk132lr/Wfsdm9ag/Uj+3gmgL02pKNnFI/7yqTP+XX59s89Afj03gtZkNmLp64umpTWoGoFz6W324+7j7Bpz1HaNahChcR47r/MOxm5O4LDUTW5nN9VzKodB72uJP79/Tamr93laaKpWN6VUG6zDR4Y1vs8Uqv5N5s4jZTyPeFt2OWaLLP3qCvBpNesyMd3dfH0ITzyn1XcZC2vfX2nov6XHzJ78fKgdoy9uyvZo/uz6fm+QZsM+7erx+pnrmT2I5f69U/YZ2Pff1kzvxOcm9MktrdvvYDyCXF0bFSVWeudl3Q4EmCZhnD66HyLfLJoO6nVKjhONhzYoWighLtz2v09f/0b/+aW9iNd/RD2oZ0nCwo5dbqQ/+3TMuJ+OtDkrkKoUiGRKhUSvWqHJe3Wbo1JrVaBP17SJKwZuODqZLW3Y+8KsqCbu1blvmz37TTLHt2ft39/gWf0U0J8HPWr+l/Z/P3G9o77X7RtHyLCn6/ynpNw98VNwvhJinz/eC+v5+6byH9uG/F079gVniuHwyeKEtXMYZcEHZo66tq2/OXaNl5rNf3Hp5bqe5/guY/15OLmtTztyJ+uLBqqmZQYx3u3Z7AgsxcNqlagYvkEz7DVxPg4LvNZy6lbk6K+gTdu7kSV5EREhDdu7sSUB3o4xl6pfAIThvrfmc3XP27qALhGll3eqjZH8gpoaVVKJgztxtQHnTtlpC2OAAASSUlEQVSvx/0h7FVSAOdbVjo1W7ZLreK41MagtxZw39jlNK/jPB9mzoZf/Rbfc4uPEy5v6XwFFogmdxVUYnwcq5+90qumVtIaVk/m+8d7MbxfK+KC1Nh9Na+TEnTG6nu3Z7Di6Ss8z794oAc3d23EQ5c7t4+GcnFz52PZa1vu0UXVizGhJS5OaGTrZF7+tCvhtU91XjCvTYOi5p0WdVOoEaJ29/tujb06arcGGdPdr23RsNnBDnNGMhpXp1fLOo4nQSd/HeR8YqxWsRztUqv6xf4na9G7pMT4oEt//+6CVK61zXpOKZ/Ikbx8/mYNq+zWpAbn169Cim211cR4IXt0f7o3CT6B8JErzqN/23o0rVUx4MJs9jkAP1gnOvciiL6LIa7OOcS0tbu9Zgjb3fWh/1iUAbah0nMivOWnJnd1Tvvgji6O2zc/35deLet4JdnyCfG8cF3boE0+xbHsqaITyI2dG/L8dW2Y+MfQNU4nL9mGnrrvbyAijldOkXSkO5n1cODVTu1r1/j+vlrWTaFhiJFOULSK65u3dAqrvNsbN3fi0Stb2I5XmVXPXOFY1ncoZ6WkBH497D9s1N4c455wKCJ0b1KDp63mN3vf1bYX+/GnXs0oNIYtucfIGFW0JMafryqK7ajPyqc/ZPbyXAFeEuZyJMGuiv94aWRXf3aa3FVMivSOXmfCdzXEW7o29lpyIRLuDl7fm7ff5jMpb8kTl3uSf3GdVycl4DIS9nsZ3+lT5j9Dg4/Q8ZT7YzdevqEdfa2Zsjd0SnVcTsNXf4eRUlWTy5E9ur9fU0qDat5XDpNXBJ7N6mY/gY4f2s3zO2hqWz5ERBARpme5+nDcY89b1EnhftsAgGBSHO4J4cR3qRT3Ut0ArWz3tAg0NyIQTe7qnPdv22Jqpc2+mudt3RuzZsSVJbz/OMbd3ZXxDm3N7k66+AhXKw3mMVsN2c5+Uxt70rula6OA8x18JZdL4MbODT2dlX+7sb3fCBi7/wztxod3Ol+JuV3YtCarn7nSNSHwtgy/+O1r5dibs+Y91pOrzq9DmwaVA17xOC1ZfINPc6S7I3+Z1UdQITH4qrIjrmnNyIGBa+bdmlT3Wo4Z4HcZRc1g9mZK+13rwlF6QyCUOkt82+lLc3Lyiqev8Nxi8bmBbUrlGIFmI796Ywf2Hj0Z9qJt4UhKdCW0P1/Vgvsva8beoydJiBO/ESCjrm3DU59nkeaw5EZJ6RqiDdzNfXK53KHz/b3bM7jzA1fbtf3mN2k1K/LO70NXArJH9/eaMPV43xZeVwPujtKalcoz9u6unhmygdzew/VZ1a9SgZFfreeOHmk89+V6GtdIZuqDF3vu+Na2QRXW/nLI8/PFCcSJ7/c6si+2Jnd1zitna4LZ9HxfEkq4Td0uJSmRz+4LPfu2NMTFCWPvLl5bfiAi4jXcMtCQu5u7NKJacrmQi5FF2wWNikblDLqgeIMA7Em0RsXAndQ9QiwJYte7dR16t67DgWOn+GLVTl4b3NHrVp7/vae7ZwZtSvkEvnu8F0kOVxJzHr2UZi+Fd0xN7uqc19magv/nq1qU2LKzwfheRv8WxMWJY1t4WVMlOZHEeKFni9olsr5UfJzwVP9WLM3e71n870xUq1jOa2irm30SlIh4lvX21TSCZcUlWvf9y8jIMMuWRXUZGqWUKjMufvkbduw/EfKWiyKy3BgTso1Ja+5KKVUGzHjoEr+FxM6EJnellCoDKpZPoGKYwyfDoUMhlVIqBmlyV0qpGKTJXSmlYpAmd6WUikGa3JVSKgaFldxFpI+IbBSRzSKS6fB6IxGZKyIrRWSNiPQr+VCVUkqFK2RyF5F44A2gL9AaGCIirX2KPQVMNMZ0BAYDb5Z0oEoppcIXTs29C7DZGLPVGHMKmAAM9CljAPeSZVWAnSillIqacEbMNwDs9+PKAXzvTzUCmCUifwIqAoHv96WUUqrUhVNzd1p9x3dBmiHAB8aYVKAf8LGI+O1bRIaKyDIRWZabmxt5tEoppcISTnLPAew3UUzFv9nlLmAigDFmIZAE+K2HaYx51xiTYYzJqFUrvFtQKaWUilw4yX0p0FxE0kWkHK4O0yk+ZbYDlwOISCtcyV2r5kopFSUhk7sxpgB4AJgJbMA1KmadiIwUkQFWsUeBP4jIamA8cLuJ1lrCSimlwlsV0hgzDZjms+0Z2+P1gP8K9EoppaJCZ6gqpVQM0uSulFIxSJO7UkrFIE3uSikVgzS5K6VUDNLkrpRSMUiTu1JKxSBN7kopFYM0uSulVAzS5K6UUjFIk7tSSsUgTe5KKRWDNLkrpVQM0uSulFIxSJO7UkrFIE3uSikVgzS5K6VUDNLkrpRSMUiTu1JKxSBN7kopFYPCSu4i0kdENorIZhHJDFDmRhFZLyLrRGRcyYaplFIqEgmhCohIPPAGcAWQAywVkSnGmPW2Ms2B4UAPY8wBEaldWgErpZQKLZyaexdgszFmqzHmFDABGOhT5g/AG8aYAwDGmD0lG6ZSSqlIhJPcGwA7bM9zrG125wHnicgPIrJIRPqUVIBKKaUiF7JZBhCHbcZhP82BnkAq8J2ItDHGHPTakchQYChAo0aNIg5WKaVUeMKpuecADW3PU4GdDmW+MMbkG2O2ARtxJXsvxph3jTEZxpiMWrVqFTdmpZRSIYST3JcCzUUkXUTKAYOBKT5lPgcuAxCRmriaabaWZKBKKaXCFzK5G2MKgAeAmcAGYKIxZp2IjBSRAVaxmcA+EVkPzAX+bIzZV1pBK6WUCk6M8W0+PzsyMjLMsmXLonJspZQ6V4nIcmNMRqhyOkNVKaVikCZ3pZSKQZrclVIqBmlyV0qpGKTJXSmlYpAmd6WUikGa3JVSKgZpcldKqRikyV0ppWKQJnellIpBmtyVUioGaXJXSqkYpMldKaVikCZ3pZSKQZrclVIqBmlyV0qpGKTJXSmlYpAmd6WUikGa3JVSKgZpcldKqRgUVnIXkT4islFENotIZpByg0TEiEjIm7cqpZQqPSGTu4jEA28AfYHWwBARae1QLgV4EFhc0kEqpZSKTDg19y7AZmPMVmPMKWACMNCh3F+Al4G8EoxPKaVUMYST3BsAO2zPc6xtHiLSEWhojPkq2I5EZKiILBORZbm5uREHq5RSKjzhJHdx2GY8L4rEAa8Cj4bakTHmXWNMhjEmo1atWuFHqZRSKiLhJPccoKHteSqw0/Y8BWgDzBORbKAbMEU7VZVSKnrCSe5LgeYiki4i5YDBwBT3i8aYQ8aYmsaYNGNMGrAIGGCMWVYqESullAopZHI3xhQADwAzgQ3ARGPMOhEZKSIDSjtApZRSkUsIp5AxZhowzWfbMwHK9jzzsJRSSp0JnaGqlFIxSJO7UkrFIE3uSikVgzS5K6VUDNLkrpRSMUiTu1JKxSBN7kopFYM0uSulVAzS5K6UUjFIk7tSSsUgTe5KKRWDNLkrpVQM0uSulFIxSJO7UkrFIE3uSikVgzS5K6VUDNLkrpRSMUiTu1JKxSBN7kopFYPCSu4i0kdENorIZhHJdHj9ERFZLyJrRGSOiDQu+VCVUkqFK2RyF5F44A2gL9AaGCIirX2KrQQyjDHtgEnAyyUdqFJKqfCFU3PvAmw2xmw1xpwCJgAD7QWMMXONMcetp4uA1JINUymlVCTCSe4NgB225znWtkDuAqafSVBKKaXOTEIYZcRhm3EsKHIrkAFcGuD1ocBQgEaNGoUZolJKqUiFU3PPARranqcCO30LiUhv4ElggDHmpNOOjDHvGmMyjDEZtWrVKk68SimlwhBOcl8KNBeRdBEpBwwGptgLiEhH4B1ciX1PyYeplFIqEiGTuzGmAHgAmAlsACYaY9aJyEgRGWAV+ytQCfiviKwSkSkBdqeUUuosCKfNHWPMNGCaz7ZnbI97l3BcSimlzoDOUFVKqRikyV0ppWKQJnellIpBmtyVUioGaXJXSqkYpMldKaVikCZ3pZSKQZrclVIqBmlyV0qpGKTJXSmlYpAmd6WUikGa3JVSKgZpcldKqRikyV0ppWKQJnellIpBmtyVUioGaXJXSqkYpMldKaVikCZ3pZSKQZrclVIqBoWV3EWkj4hsFJHNIpLp8Hp5EfmP9fpiEUkr6UCVUkqFL2RyF5F44A2gL9AaGCIirX2K3QUcMMY0A14FXirpQJVSSoUvnJp7F2CzMWarMeYUMAEY6FNmIPCh9XgScLmISMmFqZRSKhLhJPcGwA7b8xxrm2MZY0wBcAioURIBKqWUilxCGGWcauCmGGUQkaHAUOvpSRHJCuP4Z1tNYG+0g3BQVuOCshubxhUZjSsy0YqrcTiFwknuOUBD2/NUYGeAMjkikgBUAfb77sgY8y7wLoCILDPGZIQT5NmkcUWurMamcUVG44pMWY3LLZxmmaVAcxFJF5FywGBgik+ZKcBt1uNBwDfGGL+au1JKqbMjZM3dGFMgIg8AM4F44D1jzDoRGQksM8ZMAf4NfCwim3HV2AeXZtBKKaWCC6dZBmPMNGCaz7ZnbI/zgN9FeOx3Iyx/tmhckSursWlckdG4IlNW4wJAtPVEKaVijy4/oJRSMSgqyT3UcgalcLz3RGSPfeiliFQXka9FZJP1fzVru4jIa1Zsa0Skk+09t1nlN4nIbU7HijCuhiIyV0Q2iMg6EXmoLMQmIkkiskREVltxPWdtT7eWl9hkLTdRztoecPkJERlubd8oIledSVy2fcaLyEoR+aqsxCUi2SKyVkRWicgya1tZ+I5VFZFJIvKj9T3rHu24RKSF9Xty/zssIsOiHZe1v4et73yWiIy3/hai/v0qFmPMWf2Hq1N2C9AEKAesBlqX8jEvAToBWbZtLwOZ1uNM4CXrcT9gOq6x+92Axdb26sBW6/9q1uNqZxhXPaCT9TgF+AnXEg9Rjc3afyXrcSKw2DreRGCwtf1t4F7r8X3A29bjwcB/rMetrc+3PJBufe7xJfB5PgKMA76ynkc9LiAbqOmzrSx8xz4E7rYelwOqloW4bPHFA7txjd2O9ve+AbANqGD7Xt1eFr5fxfp5zvoBoTsw0/Z8ODD8LBw3De/kvhGoZz2uB2y0Hr8DDPEtBwwB3rFt9ypXQjF+AVxRlmIDkoEVQFdcEzYSfD9HXCOpuluPE6xy4vvZ2sudQTypwBygF/CVdZyyEFc2/sk9qp8jUBlXspKyFJdPLFcCP5SFuCiaaV/d+r58BVxVFr5fxfkXjWaZcJYzOBvqGGN2AVj/17a2B4qvVOO2Luk64qolRz02q+ljFbAH+BpX7eOgcS0v4XuMQMtPlMbv7B/A/wKF1vMaZSQuA8wSkeXimokN0f8cmwC5wPtWM9a/RKRiGYjLbjAw3noc1biMMb8ArwDbgV24vi/LKRvfr4hFI7mHtVRBFAWKr9TiFpFKwGRgmDHmcFmIzRhz2hjTAVdNuQvQKsgxzkpcInI1sMcYs9y+OdpxWXoYYzrhWj31fhG5JEjZsxVXAq7myLeMMR2BY7iaO6Idl+tgrrbrAcB/QxU9G3FZbfwDcTWl1Acq4vo8Ax3jrOeKSEQjuYeznMHZ8KuI1AOw/t9jbQ8UX6nELSKJuBL7WGPMp2UpNgBjzEFgHq62zqriWl7C9xie44v38hMlHVcPYICIZONanbQXrpp8tOPCGLPT+n8P8BmuE2K0P8ccIMcYs9h6PglXso92XG59gRXGmF+t59GOqzewzRiTa4zJBz4FLqQMfL+KIxrJPZzlDM4G+5IJt+Fq73Zv/x+rh74bcMi6RJwJXCki1awz/JXWtmITEcE1u3eDMebvZSU2EaklIlWtxxVwfek3AHNxLS/hFJfT8hNTgMHWqIJ0oDmwpLhxGWOGG2NSjTFpuL433xhjbol2XCJSUURS3I9x/f6ziPLnaIzZDewQkRbWpsuB9dGOy2YIRU0y7uNHM67tQDcRSbb+Nt2/r6h+v4rtbDfyWx0M/XCNDNkCPHkWjjceVxtaPq6z6l242sbmAJus/6tbZQXXzUm2AGuBDNt+7gQ2W//uKIG4LsJ1ubYGWGX96xft2IB2wEorrizgGWt7E1xf0s24LqXLW9uTrOebrdeb2Pb1pBXvRqBvCX6mPSkaLRPVuKzjr7b+rXN/p6P9OVr76wAssz7Lz3GNKikLcSUD+4Aqtm1lIa7ngB+t7/3HuEa8lJnvfST/dIaqUkrFIJ2hqpRSMUiTu1JKxSBN7kopFYM0uSulVAzS5K6UUjFIk7tSSsUgTe5KKRWDNLkrpVQM+n9UaZnbHvWzlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('second_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('second_cycle');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.freeze_to(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.860816</td>\n",
       "      <td>0.873206</td>\n",
       "      <td>0.644368</td>\n",
       "      <td>0.355632</td>\n",
       "      <td>06:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('third_cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)\n",
    "learner.load('third_cycle');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we unfreeze all the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 16:09<16:09]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.711102</td>\n",
       "      <td>0.710774</td>\n",
       "      <td>0.700436</td>\n",
       "      <td>0.299564</td>\n",
       "      <td>16:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6489' class='' max='8778', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      73.92% [6489/8778 11:33<04:04 0.6812]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr), moms=(0.8, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating prediction\n",
    "Now that the model is trained, we want to generate predictions from the test dataset.\n",
    "\n",
    "As specified in *Keita Kurita's* [article](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/), as the function ``get_preds`` does not return elements in order by default, you will have to resort the elements into their correct order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_as_nparray(ds_type) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    the get_preds method does not yield the elements in order by default\n",
    "    we borrow the code from the RNNLearner to resort the elements into their correct order\n",
    "    \"\"\"\n",
    "    preds = learner.get_preds(ds_type)[0].detach().cpu().numpy()\n",
    "    sampler = [i for i in databunch.dl(ds_type).sampler]\n",
    "    reverse_sampler = np.argsort(sampler)\n",
    "    return preds[reverse_sampler, :]\n",
    "\n",
    "test_preds = get_preds_as_nparray(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DATA_ROOT / 'sampleSubmission.csv')\n",
    "sample_submission['Sentiment'] = np.argmax(test_preds,axis=1)\n",
    "sample_submission.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0    156061          2\n",
       "1    156062          2\n",
       "2    156063          2\n",
       "3    156064          2\n",
       "4    156065          2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=predictions.csv>Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "# create a link to download the dataframe which was saved with .to_csv method\n",
    "create_download_link(filename='predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now submit our predictions to Kaggle !  In our example, without playing too much with the parameters, we get a score of 0.70059, which leads us to the 5th position on the leaderboard! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this NoteBook, I explain how to combine the ``transformers`` library with the beloved ``fastai`` library. It aims to make you understand where to look and modify both libraries to make them work together. Likely, it allows you to use **Slanted Triangular Learning Rates**, **Discriminate Learning Rate** and even **Gradual Unfreezing**. As a result, without even tunning the parameters, you can obtain rapidly state-of-the-art results.\n",
    "\n",
    "This year, the transformers became an essential tool to NLP. Because of that, I think that pre-trained transformers architectures will be integrated soon to future versions of fastai. Meanwhile, this tutorial is a good starter.\n",
    "\n",
    "I hope you enjoyed this first article and found it useful.Â \n",
    "Thanks for reading and don't hesitate in leaving questions or suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* Hugging Face, Transformers GitHub (Nov 2019), [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)\n",
    "* Fast.ai, Fastai documentation (Nov 2019), [https://docs.fast.ai/text.html](https://docs.fast.ai/text.html)\n",
    "* Jeremy Howard & Sebastian Ruder, Universal Language Model Fine-tuning for Text Classification (May 2018), [https://arxiv.org/abs/1801.06146](https://arxiv.org/abs/1801.06146)\n",
    "* Keita Kurita's articleÂ : [A Tutorial to Fine-Tuning BERT with Fast AI](https://mlexplained.com/2019/05/13/a-tutorial-to-fine-tuning-bert-with-fast-ai/)Â (May 2019)\n",
    "* Dev Sharma's articleÂ : [Using RoBERTa with Fastai for NLP](https://medium.com/analytics-vidhya/using-roberta-with-fastai-for-nlp-7ed3fed21f6c) (Sep 2019)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
